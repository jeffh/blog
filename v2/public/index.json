[{"content":"Background Since migrating this site to Hugo, I felt like it was finally time to avoid learning TOML.\nThis assumes you don\u0026rsquo;t know TOML but know other data formats? Time to speedrun through.\nThe 30-second Start You can think of toml as key value file format with namespace prefixes that translate to JSON:\n# this is a comment key = \u0026#34;value\u0026#34; [my-key-prefix] key2 = \u0026#34;value2\u0026#34; person.name = \u0026#34;John\u0026#34; Conceptually produces\n{ \u0026#34;key\u0026#34;: \u0026#34;value\u0026#34;, \u0026#34;my-key-prefix\u0026#34;: { \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34; }, \u0026#34;person\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;John\u0026#34; } } Dot-notation indicates a nested object. In the spec, TOML calls objects tables.\nYou can alternatively do inlined tables:\nperson = { given = \u0026#34;John\u0026#34;, family = \u0026#34;Doe\u0026#34; } { \u0026#34;person\u0026#34;: { \u0026#34;given\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;family\u0026#34;: \u0026#34;Doe\u0026#34; } } Types The following basic types are supported for values:\nstrings can be quoted or double quoted. They can also by triple quoted like python strings for multiline support. integers booleans hex (with 0x prefix) octal (with 0o prefix) fractions / floats exponents (using e or E) NaN and Infinity like Javascript arrays using [] maps using {} dates \u0026amp; times using RFC3339 format without any strings (eg - 2024-09-19T14:22:16-07:00). You can provide be date only or time only Note that keys must always be strings (like JSON).\nDot Notation The dot notation keys produces nested objects:\nfruit.apple.smooth = true Produces\n{ \u0026#34;fruit\u0026#34;: { \u0026#34;apple\u0026#34;: { \u0026#34;smooth\u0026#34;: true } } } Although dots in keys are not considered good practice because we should be using sections instead.\nSections Sections remove repetition of the same prefix for sets of keys:\n# this is family.given = \u0026#34;John\u0026#34; family.family = \u0026#34;Doe\u0026#34; # equivalent to [person] given = \u0026#34;John\u0026#34; family = \u0026#34;Doe\u0026#34; { \u0026#34;person\u0026#34;: { \u0026#34;given\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;family\u0026#34;: \u0026#34;doe\u0026#34; } } Appending to Arrays Sections with double the brackets indicates appending an object into an array:\n[[people]] given = \u0026#34;John\u0026#34; family = \u0026#34;Doe\u0026#34; [[people]] given = \u0026#34;Jane\u0026#34; family = \u0026#34;Doe\u0026#34; { \u0026#34;people\u0026#34;: [ { \u0026#34;given\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;family\u0026#34;: \u0026#34;Doe\u0026#34; }, { \u0026#34;given\u0026#34;: \u0026#34;Jane\u0026#34;, \u0026#34;family\u0026#34;: \u0026#34;Doe\u0026#34; } ] } Nesting still works with appends:\n[[cool.people]] given = \u0026#34;John\u0026#34; family = \u0026#34;Doe\u0026#34; { \u0026#34;cool\u0026#34;: { \u0026#34;people\u0026#34;: [ { \u0026#34;given\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;family\u0026#34;: \u0026#34;Doe\u0026#34; } ] } } That\u0026rsquo;s pretty much it!\n","permalink":"http://localhost:1313/writings/2024/toml-crashcourse/","summary":"\u003ch1 id=\"background\"\u003eBackground\u003c/h1\u003e\n\u003cp\u003eSince migrating this site to \u003ca href=\"https://gohugo.io/\"\u003eHugo\u003c/a\u003e, I felt like it was finally time to\navoid learning TOML.\u003c/p\u003e\n\u003cp\u003eThis assumes you don\u0026rsquo;t know \u003ca href=\"https://toml.io/\"\u003eTOML\u003c/a\u003e but know other \u003ca href=\"https://www.json.org/\"\u003edata\u003c/a\u003e\n\u003ca href=\"https://yaml.org/\"\u003eformats\u003c/a\u003e? Time to speedrun through.\u003c/p\u003e\n\u003ch1 id=\"the-30-second-start\"\u003eThe 30-second Start\u003c/h1\u003e\n\u003cp\u003eYou can think of toml as key value file format with namespace prefixes that\ntranslate to JSON:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-toml\" data-lang=\"toml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# this is a comment\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003ekey\u003c/span\u003e = \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;value\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e[\u003cspan style=\"color:#a6e22e\"\u003emy-key-prefix\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003ekey2\u003c/span\u003e = \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;value2\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003eperson\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e = \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;John\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eConceptually produces\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#f92672\"\u003e\u0026#34;key\u0026#34;\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;value\u0026#34;\u003c/span\u003e,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#f92672\"\u003e\u0026#34;my-key-prefix\u0026#34;\u003c/span\u003e: {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\u003cspan style=\"color:#f92672\"\u003e\u0026#34;key2\u0026#34;\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;value2\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t},\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\u003cspan style=\"color:#f92672\"\u003e\u0026#34;person\u0026#34;\u003c/span\u003e: {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t\t\u003cspan style=\"color:#f92672\"\u003e\u0026#34;name\u0026#34;\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;John\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\t}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eDot-notation indicates a nested object. In the spec, TOML calls objects tables.\u003c/p\u003e","title":"Toml Crash Course"},{"content":"One of the most interesting parts of generative testing (aka QuickCheck). Is state machine testing. The original purpose I built Fox was to explore state machine testing. In particular, the talk from John Hughes video was inspirational to exploring this further:\nIn short, John makes a case: dynamically generating state machines to detect errors that is more effective and economical than traditional example based tests. There\u0026rsquo;s lots of work managing example based tests that can be better solved with generative testing.\nWhile I doubt John wants to completely replace example-based tests, it seems like that example-based tests should be relegated to smaller roles in a test suite:\nEnsuring no regression of a bug occurs again, or ensuring specific happy-path case is always tested. Testing pure functions (arguably, normal generative testing can help too) With the most common argument against generating testing comes with the complexity of writing generative tests, or more specifically:\nIsn\u0026rsquo;t writing a generative test equivalent to implementing the code I\u0026rsquo;m testing?\nAnd that logically feels true. What\u0026rsquo;s the benefit of implementing a state machine that basically implements the same behavior again?\nJohn\u0026rsquo;s example in the video attempts to show the difference: that a production implementation has many complected details that a native implementation ignores. And if your state machine is implemented at a higher-level, that\u0026rsquo;s still simpler than the subject under test. 1\nAnother way to look at this argument is how proof checking programming languages defend themselves. Proof checking languages receive similar push back – that if you\u0026rsquo;re specifying enough detail to proof your program correctness, isn\u0026rsquo;t that effectively the same as implementing it in a programming language that can execute it as well? Leslie Lamport states his case for TLA+:\nI do know, for most computer programmers and engineers, TLA+ provides a new way of thinking about what they do. And this makes them better programmers and engineers, even in cases when TLA+ language and tools are not useful.\nFurthermore, Brannon Batson (an Intel Engineer) says:\nThe hard part of learning to write TLA+ specs is learning to think abstractly about the system. With experience, engineers learn how to do it. Being able to think abstractly improves their design process.\nDoesn\u0026rsquo;t that sound a bit like what TDD proponents argue? That writing (example-based) specifications helps drive out the design? Similar arguments come from strongly-typed language enthusiasts as well. 2\nGenerative state machine testing is a (significantly) weaker version of a proof checker. It doesn\u0026rsquo;t guarantee incorrect values, only probabilistically.\nIntroducing check.statem Unfortunately, I don\u0026rsquo;t do any work in Erlang, so I\u0026rsquo;ve been working on writing a state machine generator based on the papers \u0026amp; talks of John Hughes. It\u0026rsquo;s called check.statem.\nIt\u0026rsquo;s possible to built a basic state machine, one that has little to no dependencies on another transition:\n(gen/vector (gen/one-of gen-puts gen-gets)) But it gets more complicated when transitions shares dependencies. That\u0026rsquo;s what check.statem attempts to support.\ncheck.statem is built on top of test.check and currently only provides two features: defining state machines and a generator that produces programs from a state machine.\nLike all other generators in test.check, check.statem will shrink values to the \u0026ldquo;smallest\u0026rdquo; possible value. This means generated programs shrink in size (number of statements) and parameters (associated data for each statement), all while conforming to the model state machine.\nUnlike traditional state machines, there\u0026rsquo;s several bits of information to encode on a per transition basis:\nWhen is the transition applicable to use, given the current state of the model? What is associated data for the transition, potentially using the current state of the model? What is the assertion after each transition is followed? From each of those requirements, then check.statem can properly generate programs. And it can determine if removing a statement from a generated program is valid operation (or breaks the constraints of the model state machine).\n;; test.check requires elided (require \u0026#39;[net.jeffhui.check.statem :refer [defstatem cmd-seq run-cmds]]) ;; defining a state machine (defstatem key-value-statem ;; name of the state machine [mstate] ;; the internal model state -- starts as nil ;; define transitions (:put ;; name of the transition (args [] [gen/keyword gen/any-printable-equatable]) ;; associated data generators for this transition (advance [_ [_ k value]] ;; next-mstate given the generated data and the current mstate (assoc mstate k value))) (:get ;; precondition for this transition to be utilized (here: we must have stored something) (assume [] (pos? (count mstate))) (args [] [(gen/elements (keys mstate))]) ;; generate values from model state ;; postcondition assertion: check model state against the return value of the subject-under-test ;; implementation. (verify [_ [_ k] return-value] (= (mstate k) return-value)))) ;; define a property to test: `kv-interpreter` is a constructor of the subject ;; under test ;; ;; `kv-interpreter` returns a function that accepts a transition and returns ;; the value that the SUT would return for the model state machine to verify. ;; ;; commands are in the vector format: ;; ;; [command-name-kw generated-args...] ;; for example: ;; [:put :f23] ;; [:get 3] ;; (defspec kv-spec 100 (for-all [cmds (cmd-seq key-value-statem)] (:ok? (run-cmds key-value-statem cmds (kv-interpreter (atom [])))))) It\u0026rsquo;s still relatively new (only snapshots versions are on Clojars right now), but I\u0026rsquo;ve been writing some code in an example project to play around an it\u0026rsquo;s been enlightening from first-hand experience. The kind of signal-to-noise that John mentions happens on a regular basis that still surprises (and delights) me: \u0026ldquo;There\u0026rsquo;s no way this is the smallest test case.\u0026rdquo;\nWhat\u0026rsquo;s left until 1.0.0 of check.statem? It\u0026rsquo;s mostly solidifying debugging and usability of the API.\nCurrently check.statem could provide better debugging information when it does find a failing test case And defining state machines can be complex. While the current way is serviceable, there should be a better approach. More testing to verify it\u0026rsquo;s shrinking behavior Future Work There\u0026rsquo;s some interesting personal experiences about using generative state machine testing that should be written up at some point.\nIn terms of features for check.statem, the Erlang QuickCheck does have some really nice features when in comes to parallel testing that I would want to implement at some point in the future.\nTo specify the behavior at a higher level makes a C-like quickcheck less valuable than a QuickCheck implemented in a functional language.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBoth positions seem a bit idealistic, but they have some kernel of truth. Anything that forces you to deviate from your normal style of thinking will typically make you stop and consider more perspectives.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/2020/01-check.statem.html","summary":"\u003cp\u003eOne of the most interesting parts of generative testing (aka\n\u003ca href=\"https://hackage.haskell.org/package/QuickCheck\"\u003eQuickCheck\u003c/a\u003e). Is state machine testing. The original purpose I\nbuilt \u003ca href=\"http://github.com/jeffh/Fox\"\u003eFox\u003c/a\u003e was to explore state machine testing. In particular, the talk\nfrom John Hughes video was inspirational to exploring this further:\u003c/p\u003e\n\n\n\n\u003cp\u003e\n\u003ciframe class=\"center lit\" width=\"560\" height=\"315\"\nsrc=\"https://www.youtube-nocookie.com/embed/zi0rHwfiX1Q\" frameborder=\"0\"\nallow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\nallowfullscreen\u003e\u003c/iframe\u003e\n\u003c/p\u003e\n\n\u003cp\u003eIn short, John makes a case: dynamically generating state machines to detect\nerrors that is more effective and economical than traditional example based\ntests. There\u0026rsquo;s lots of work managing example based tests that can be better\nsolved with generative testing.\u003c/p\u003e","title":"check.statem: Generating Test Programs"},{"content":"I\u0026rsquo;m fascinated by how engineers read and interpret code that they work on a daily basis. It\u0026rsquo;s no doubt different for everyone, but few explain how they go about and understand a unfamiliar codebase.\nFor me, being comfortable in a codebase usually means two things:\nBeing able to jump to relevant, related parts of the code. Understand the implications of changing a piece of code Inside the system – impact of code quality. How does the code influence code in the same project? Outside the system – implications for human and program collaborators. How does the code influence other projects, teams, or users? Both can be addressed by following the data flow of the code. I refer to my strategy as assertions and assumptions. Take this arbitrary code snippet from Django:\n# from django/forms/models.py def fields_for_model(model, fields=None, exclude=None, widgets=None, formfield_callback=None, localized_fields=None, labels=None, help_texts=None, error_messages=None, field_classes=None): field_list = [] ignored = [] opts = model._meta # Avoid circular import from django.db.models.fields import Field as ModelField sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)] for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)): if not getattr(f, \u0026#39;editable\u0026#39;, False): if (fields is not None and f.name in fields and (exclude is None or f.name not in exclude)): raise FieldError( \u0026#34;\u0026#39;%s\u0026#39; cannot be specified for %s model form as it is a non-editable field\u0026#34; % ( f.name, model.__name__) ) continue if fields is not None and f.name not in fields: continue if exclude and f.name in exclude: continue kwargs = {} if widgets and f.name in widgets: kwargs[\u0026#39;widget\u0026#39;] = widgets[f.name] if localized_fields == ALL_FIELDS or (localized_fields and f.name in localized_fields): kwargs[\u0026#39;localize\u0026#39;] = True if labels and f.name in labels: kwargs[\u0026#39;label\u0026#39;] = labels[f.name] if help_texts and f.name in help_texts: kwargs[\u0026#39;help_text\u0026#39;] = help_texts[f.name] if error_messages and f.name in error_messages: kwargs[\u0026#39;error_messages\u0026#39;] = error_messages[f.name] if field_classes and f.name in field_classes: kwargs[\u0026#39;form_class\u0026#39;] = field_classes[f.name] if formfield_callback is None: formfield = f.formfield(**kwargs) elif not callable(formfield_callback): raise TypeError(\u0026#39;formfield_callback must be a function or callable\u0026#39;) else: formfield = formfield_callback(f, **kwargs) if formfield: field_list.append((f.name, formfield)) else: ignored.append(f.name) field_dict = OrderedDict(field_list) if fields: field_dict = OrderedDict( [(f, field_dict.get(f)) for f in fields if ((not exclude) or (exclude and f not in exclude)) and (f not in ignored)] ) return field_dict Without looking much into the other code around it, we can make (roughly) two kinds of interferences: assumptions and assertions in alternating fashion.\n1. Assumptions This code probably has to deal with html formdata handling based on the name and project (django being a web framework) It seems to be a public method because the function\u0026rsquo;s name isn\u0026rsquo;t prefixed with an underscore for private / protected functions as per python\u0026rsquo;s coding conventions There\u0026rsquo;s also no other private or protected indicator that may indicate that if the developer was for accustomed to programming in another language. The function name indicates getting some fields (a collection?) given a model (a form model?) 2. Assertions This code loops over fields specified in the Model\u0026rsquo;s _meta field. This function returns an OrderedDict type. The keys are the field\u0026rsquo;s name property and the values are something called a formfield. Form fields are constructed with kwargs map that the loop spends most of its time building. Form fields are sortable. There is a special case handled for Django\u0026rsquo;s database models. widgets, localized_fields, labels, help_texts, error_messages, field_classes is dictionary-like with field names as keys. formfield_callback is a callable (aka - function) fields and exclude are list-like f.name is hashable and support equality 3. Assumptions FormFields must be some class. They may be different from regular Field classes, or they could be related via inheritance or abstract base-class. If this code wasn\u0026rsquo;t python, then could also be an interface. fields and exclude are probably whitelists and blacklists respectively formfield_callback is an alternative constructor for these formfield instances It looks like this function read\u0026rsquo;s some or all of a models\u0026rsquo; fields. Models are from the database or elsewhere. The return value is a dictionary of field names to some field model. This cycle of assumptions and assertions can be repeated as many times as needed. Exploring more code that is related will help convert some assumptions into assertions (eg - jumping to a piece of code that uses this function). But the goal is to build a collection of assertions you can make about the code at any given point in time.\nNavigating through the Code Navigating through code is primarily driven by the need to convert assumptions into assertions. In the example above, I happened to pick a piece of code at random. But usually exploring a codebase is driven by a goal – usually to make a change to the software.\nWhen I navigate down into more implementation details, the goal is to understand how or what is being accomplish in a piece of code. This means I need to understand how a piece of code works, what arguments a function or class expects, etc.\nLearning context of the a given code\u0026rsquo;s execution when I navigate up to find usages of the code I was reading. This helps understand the bigger picture of why the some code was written and if it can make assumptions about its execution. It\u0026rsquo;s only natural for a function to be implemented against the cases it\u0026rsquo;s known to encounter.\nImplications In short:\nDon\u0026rsquo;t trust names of things. The human language is a highly context-specific form of communication. Original meanings are easily lost to time. Never trust names of things unless you have verified it yourself. Code is always contextual to decisions both inside and outside the codebase. Since time changes the context, code must also change over time. Even if you don\u0026rsquo;t use a strongly-typed language, it is still valuable to think in terms of how a type checker works. ","permalink":"http://localhost:1313/2016/23-reading-code.html","summary":"\u003cp\u003eI\u0026rsquo;m fascinated by how engineers read and interpret code that they work on a\ndaily basis. It\u0026rsquo;s no doubt different for everyone, but few explain how they go\nabout and understand a unfamiliar codebase.\u003c/p\u003e\n\u003cp\u003eFor me, being comfortable in a codebase usually means two things:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBeing able to jump to relevant, related parts of the code.\u003c/li\u003e\n\u003cli\u003eUnderstand the implications of changing a piece of code\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInside the system\u003c/strong\u003e – impact of code quality. How does the code influence\ncode in the same project?\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOutside the system\u003c/strong\u003e – implications for human and program collaborators.\nHow does the code influence other projects, teams, or users?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBoth can be addressed by following the data flow of the code. I refer to my\nstrategy as assertions and assumptions. Take this arbitrary\n\u003ca href=\"https://github.com/django/django/commit/4bc6b939944183533ae74791d21282e613f63a96\"\u003ecode snippet\u003c/a\u003e\nfrom \u003ca href=\"https://github.com/django/django\"\u003eDjango\u003c/a\u003e:\u003c/p\u003e","title":"Reading Code – Assertions \u0026 Assumptions"},{"content":"When evaluating companies, its utmostly important to learn about the engineering culture. Culture for a company is simular to scope for code – culture provides a context for getting work done.\nCompanies advertise their culture, but note that each company has a different culture. There\u0026rsquo;s plenty of articles about culture, so I won\u0026rsquo;t bother covering that. Just remember they aren\u0026rsquo;t necessarily the same. Companies tend not to be explicit about making sure their process matches what you expect. Be suspicious for a company that can\u0026rsquo;t explain it\u0026rsquo;s culture because that just means they\u0026rsquo;re not activitely trying to cultivate one. And that means it\u0026rsquo;s implicitly defined by the leaders of the company. Even if they choose not to define it.\nBasics There are some basics that should be generally applicable to most companies:\nDeployment frequency. There should be a process for deployments that in less than a month. And that process should be hassle-free. And by hassle-free, it usually means it\u0026rsquo;s an automated script to do the entire deploy. Feedback loops for code. How does code that gets written become vetted to run in production? There should be multiple points that verify the code: some automated (eg - CI) and some human-review (eg - code review). Prioritization. How do new features get prioritized for engineering? How is the engineering\u0026rsquo;s work communicated to the rest of the organization? Is the business promised upfront before engineering is told about the feature. Or is engineering involved in helping how the business prioritizes work? While it\u0026rsquo;s possible for some companies to not do one of the ones listed, they should have good reasons to why not. Otherwise look suspiciously.\nSustainability Hopefully the company has the basics down. Next are things you\u0026rsquo;ll usually have to ask about. Larger companies more likely have these things, but it\u0026rsquo;s worth noting that these are important for companies larger than a handful of people:\nAre there regular one-on-ones? No doubt large companies have this. That\u0026rsquo;s because one-on-one is a safer way for some employees to voice concerns. But a scheduled one-on-one provides a useful way to raise concerns privately without having to require employees the initiate the effort. Are there regular retrospectives? Not just the one for that outage that occurred yesterday, but a regular one. It\u0026rsquo;s similar to a one-on-one, but for teams. They provide ways for a team to raise concerns. The scheduled time reinfornces that this kind of feedback loop is valued. Do employees work long hours? It\u0026rsquo;s not necessarily bad when employees work overtime. It could be a sign of engineers invested in the product or a specific time-sensitive deadline. But a common occurrence of late nights isn\u0026rsquo;t healthy. Longer hours sacrifices the longer-term sustainability. Companies should make it clear why employees work longer hours for new employees if that isn\u0026rsquo;t expected of them. Otherwise the social pressure can drive the same effect. These are indications that the company has set some roots down with an eye on the long-term future. Tiny startups don\u0026rsquo;t have this because they\u0026rsquo;re looking for the power-users of their product.\nGrowth Finally, companies can go above an beyond if they are willing in invest in your continual refinement of your craft. Few companies do this. To be fair, a lot of it does depend on the person. It\u0026rsquo;s difficult for an organization to offer this well.\nDoes the company provide resources to attend/speak at conferences? It\u0026rsquo;s a useful way to network with the community at large. Resources could be monetary or training. Does the company offer time to do alternative work from the day-to-day? An easy way is to offer some time free for personal learning, contributing to open source, or working on talks. Think like Google 20% or Facebook\u0026rsquo;s Hackweek. Does the company provide a process for evaluating and introducing new technologies? Besides just throwing employees into the deep-end, there should be ways for to help explore and train with new technologies. How does the company train junior developers? Unfortunately, there isn\u0026rsquo;t an obvious answer to this. But is important for the company\u0026rsquo;s bus-factor. Teaching a useful way to solidify knowledge for senior developers. Sadly not every developer will like doing this. This is by no means conclusive, but this is a useful checklist to start with. How does your company compare?\n","permalink":"http://localhost:1313/2016/22-whats-your-engineering-culture.html","summary":"\u003cp\u003eWhen evaluating companies, its utmostly important to learn about the engineering\nculture. Culture for a company is simular to scope for code – culture provides a\ncontext for getting work done.\u003c/p\u003e\n\u003cp\u003eCompanies advertise their culture, but note that each company has a different\nculture. There\u0026rsquo;s plenty of articles about culture, so I won\u0026rsquo;t bother covering\nthat. Just remember they aren\u0026rsquo;t necessarily the same. Companies tend not to be\nexplicit about making sure their process matches what you expect. Be suspicious\nfor a company that can\u0026rsquo;t explain it\u0026rsquo;s culture because that just means they\u0026rsquo;re\nnot activitely trying to cultivate one. And that means it\u0026rsquo;s implicitly defined\nby the leaders of the company. Even if they choose not to define it.\u003c/p\u003e","title":"What's Your Engineering Culture?"},{"content":"Trying to concisely describe concepts is an interesting exercise. The ideal goal is to build upon existing concepts, but as you add more concepts you run the risk of being inconsistent.\nSo with at most two sentences, I present a list of common programming concepts. This goes without warning that lossy compression is inevitable.\nData: Ones and zeros. Values: Meaningful data. Types / Encodings: Interpretations of values. State: A value that changes over time. Usually also considered a Value. Variables: Names for values over time. Collections: A value that\u0026rsquo;s a a group of values of same type. Structs: A value that\u0026rsquo;s a group of values with possibly differing types. Classes: Structs with functions that have itself as the first argument. Inheritance: A concise way to implement a class by referring to part of its implementation from one class. Multiple Inheritance: A class that inherits from multiple other classes. Extensions: Adding methods to a previously defined type. Mixins: Adding (Multiple) Inheritance to a previously defined type. Interface / Protocols: Inheritance of a class that has only functions that should be implemented by the class that inherits it. Traits: Interfaces that may have function implementations. Generics: Treating a type as a variable. Allows algorithms independent of specific types. Type Classes: Generic Interfaces. Monad: An interface defining the expected behavior for map. Functor: An interface defining the expected behavior for apply. Pointers: A value that indicates where to find another value. An home address is a pointer to a home. Big-O Notation: A method to estimate the number of main-memory operations Slice: A value that is a pointer and length into an existing collection Value Objects: An struct / class with equality and hashCode semantics. Object-Oriented Programming: The concept of classes talking to each other using value objects. Procedure: A sequence of operations to execute. Most programming languages mean procedure when they say function. Function: Vaguely defined / blurred by current norms. See Procedure. Pure Function: A procedure that returns the same output for the same inputs. Side Effects: Any observable state that occurs besides a return value. Functional Programming: The practice of using less state and more pure functions. Code: A value that is a series of operations AST (Abstract Syntax Tree): Hierarchy of typed code Program: A collection of code that a computer that can execute. Compiler: Program that take code and produce programs. Interpreter: A program that executes code without producing a program. Emulator: A program that mimics the behavior of hardware. Virtual Machine: A computer emulator where the hardware may not actually exist (eg - Java Virtual Machine). Static: Known at compile-time. Dynamic: Known at execution-time. Type Checker: A program that validates what types flowing through your code. Type Inference: A compiler or interpreter feature can that deduce types without always explicitly specifying it in code. Optimization: Writing code for the computer first, instead of humans. Performance: Turning memory operations for lower frequency, and higher throughput. Reference Counting: Counting number of owners of a piece of memory to know when to free it. Garbage Collection: An embedded program that frees another program\u0026rsquo;s memory that is no longer being used. Reflection: Code that can inspect and/or modify itself as it\u0026rsquo;s executing. Macros: An operation that can be translated to a sequence of operations before program execution. JIT (Just-In-Time) Compilation: A feature of interpreters or emulators that compiles code during its execution. The last concept pushes the limits of definitions this concise. Some interesting implications result from these definitions:\nHow would you describe a library in at most two sentences? Does it match with conventional definitions of libraries in interpreted languages? Does it match with conventional definitions of libraries in compiled languages? How would you describe a plugin? How does it differ from library? Is the assert replacement in pytest a macro? Is Clojure a compiler or intepreter in these definitions? Clojure code always compiles to bytecode before executing (eg - in a REPL) Clojure code can be compiled ahead-of-time into a jar Is a Python an Interpreter or Compiler in these definitions? It produces bytecode to disk, before running it Suggestions for more concise definitions or comments, just tweet me.\n","permalink":"http://localhost:1313/2016/21-tldr-programming-concepts.html","summary":"\u003cp\u003eTrying to concisely describe concepts is an interesting exercise. The ideal goal\nis to build upon existing concepts, but as you add more concepts you run the\nrisk of being inconsistent.\u003c/p\u003e\n\u003cp\u003eSo with at most two sentences, I present a list of common programming concepts.\nThis goes without warning that lossy compression is inevitable.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eData\u003c/strong\u003e: Ones and zeros.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eValues\u003c/strong\u003e: Meaningful data.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTypes / Encodings\u003c/strong\u003e: Interpretations of values.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eState\u003c/strong\u003e: A value that changes over time. Usually also considered a Value.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVariables\u003c/strong\u003e: Names for values over time.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCollections\u003c/strong\u003e: A value that\u0026rsquo;s a a group of values of same type.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStructs\u003c/strong\u003e: A value that\u0026rsquo;s a group of values with possibly differing types.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eClasses\u003c/strong\u003e: Structs with functions that have itself as the first argument.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInheritance\u003c/strong\u003e: A concise way to implement a class by referring to part of\nits implementation from one class.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMultiple Inheritance\u003c/strong\u003e: A class that inherits from multiple other classes.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExtensions\u003c/strong\u003e: Adding methods to a previously defined type.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMixins\u003c/strong\u003e: Adding (Multiple) Inheritance to a previously defined type.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInterface / Protocols\u003c/strong\u003e: Inheritance of a class that has only functions that\nshould be implemented by the class that inherits it.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTraits\u003c/strong\u003e: Interfaces that may have function implementations.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGenerics\u003c/strong\u003e: Treating a type as a variable. Allows algorithms independent of\nspecific types.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eType Classes\u003c/strong\u003e: Generic Interfaces.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMonad\u003c/strong\u003e: An interface defining the expected behavior for \u003ccode\u003emap\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFunctor\u003c/strong\u003e: An interface defining the expected behavior for \u003ccode\u003eapply\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePointers\u003c/strong\u003e: A value that indicates where to find another value. An home\naddress is a pointer to a home.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBig-O Notation\u003c/strong\u003e: A method to estimate the number of main-memory operations\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSlice\u003c/strong\u003e: A value that is a pointer and length into an existing collection\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eValue Objects\u003c/strong\u003e: An struct / class with equality and hashCode semantics.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eObject-Oriented Programming\u003c/strong\u003e: The concept of classes talking to each other\nusing value objects.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eProcedure\u003c/strong\u003e: A sequence of operations to execute. Most programming languages\nmean procedure when they say function.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFunction\u003c/strong\u003e: Vaguely defined / blurred by current norms. See Procedure.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePure Function\u003c/strong\u003e: A procedure that returns the same output for the same\ninputs.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSide Effects\u003c/strong\u003e: Any observable state that occurs besides a return value.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFunctional Programming\u003c/strong\u003e: The practice of using less state and more pure\nfunctions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCode\u003c/strong\u003e: A value that is a series of operations\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAST (Abstract Syntax Tree)\u003c/strong\u003e: Hierarchy of typed code\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eProgram\u003c/strong\u003e: A collection of code that a computer that can execute.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCompiler\u003c/strong\u003e: Program that take code and produce programs.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInterpreter\u003c/strong\u003e: A program that executes code without producing a program.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmulator\u003c/strong\u003e: A program that mimics the behavior of hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVirtual Machine\u003c/strong\u003e: A computer emulator where the hardware may not actually\nexist (eg - Java Virtual Machine).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStatic\u003c/strong\u003e: Known at compile-time.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDynamic\u003c/strong\u003e: Known at execution-time.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eType Checker\u003c/strong\u003e: A program that validates what types flowing through your\ncode.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eType Inference\u003c/strong\u003e: A compiler or interpreter feature can that deduce types\nwithout always explicitly specifying it in code.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOptimization\u003c/strong\u003e: Writing code for the computer first, instead of humans.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePerformance\u003c/strong\u003e: Turning memory operations for lower frequency, and higher\nthroughput.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReference Counting\u003c/strong\u003e: Counting number of owners of a piece of memory to know\nwhen to free it.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGarbage Collection\u003c/strong\u003e: An embedded program that frees another program\u0026rsquo;s\nmemory that is no longer being used.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReflection\u003c/strong\u003e: Code that can inspect and/or modify itself as it\u0026rsquo;s executing.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMacros\u003c/strong\u003e: An operation that can be translated to a sequence of operations\nbefore program execution.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJIT (Just-In-Time) Compilation\u003c/strong\u003e: A feature of interpreters or emulators\nthat compiles code during its execution.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThe last concept pushes the limits of definitions this concise. Some interesting\nimplications result from these definitions:\u003c/p\u003e","title":"TLDR Programming Concepts"},{"content":"When someone talks about abstractions, they\u0026rsquo;re usually trying to make the software more flexible. But that\u0026rsquo;s usually one of two kinds of abstractions.\nBuild an abstraction to hide an implementation Abstractions that hide implementations are more commonly touted as good designs. Ruby\u0026rsquo;s Faraday abstracts the specific HTTP library implementation. Rails\u0026rsquo; ActiveRecord abstracts the SQL you need to write to interface with a relational database. The Data Mapper Pattern abstracts the persistent storage from your application.\nA recent example of this kind of abstraction I\u0026rsquo;ve done is integrate with payment processors. Here\u0026rsquo;s a theoretical example of an interface to accept payments:\n// Java: Just because it\u0026#39;s concise for defining interfaces class Payment { ... } // Value class PaymentResponse { // Tuple of Error and updated Payment public Error error; public Payment payment; } interface PaymentProcessor { // Return a response that indicates success, or failure and // a Payment object for persistence and the UI. PaymentResponse startPayment(Order order) // Take a given set of input from the UI // Return a response that indicates success, or failure and // an updated Payment object for persistence. PaymentResponse updatePayment( Order order, Payment payment, FrontEndInputParameters input ) // Authorize a payment to ensure we can charge this payment // Return a response that indicates success, or failure and // optionally can update the payment PaymentResponse authorizePayment( Order order, Payment payment ) // Charge a payment and collect money. // Return a response that indicates success, or failure and // optionally can update the payment (eg - store charge id) PaymentResponse capturePayment( Order order, Payment payment ) // Refund a charged payment and return the money // Return a response that indicates success, or failure and // optionally can update the payment (eg - indicate its been // fully refunded) PaymentResponse refundPayment( Order order, Payment payment, int amountInCents ) } This kind of abstraction is usually more procedural — following an ordered series of method invocations.\nPayment interface above could possible support many implementations:\nStripe Braintree Store Credit Admin Adjustments The consumer of the PaymentProcessor interface doesn\u0026rsquo;t need to know anything about how payments are processed with the exception of these methods. Any payment system that works similarly to what PaymentProcessor expects can easily replace what\u0026rsquo;s there.\nIn more dynamic languages, such as Python or Ruby, these interfaces may be implicitly assumed, but it\u0026rsquo;s valuable to explicitly define them. Well-designed RPC-styled micro-services also fit these kinds of abstractions.\nImplementation-hiding abstractions are usually few and far between. There\u0026rsquo;s usually not a good reason to hide implementations that don\u0026rsquo;t interact with code you don\u0026rsquo;t control. There\u0026rsquo;s not much benefit to hiding implementations for code you control — since that\u0026rsquo;s akin to code organization.\nBuild an abstraction to compose the solution The second kind of abstraction is breaking the core problem down into a small set of composable pieces. Each piece may not necessarily be small, but each piece shouldn\u0026rsquo;t repeat work that can be isolated and composed.\nA well-trodden path is parsing text. There\u0026rsquo;s many talks and articles that demonstrate composing smaller parsers into larger ones. Data mapping between two similar data structures is a related problem that also has relatively clear composition traits. Composing a solution gives future flexibility to adapt to changing requirements of the problem being solve.\nIn composable abstraction, interfaces define how each piece communicates to one another. An interface for composability looks less procedural, and more functional:\n// Java class Node { // Value public String name; public Collection\u0026lt;Node\u0026gt; children; } // How we read characters. Not well defined but just to // illuminate the implementation of parsers class Stream { int getOffset() { ... } void setOffset(int newOffset) { ... } Character get() { ... } boolean isEndOfStream() { ... } } interface Parser { Collection\u0026lt;Node\u0026gt; parse(Stream stream); } Parsers can be composed by passing parsers into each others constructors:\n// Parses if the stream starts with \u0026lt;literal\u0026gt; by returning // that literal as a Node class TextParser implements Parser { TextParser(String literal) { ... } Collection\u0026lt;Node\u0026gt; parse(Stream stream) { .. } } // Parses if the stream satisfies multiple parsers and returns // the concatenation of all those parser results class SequenceParser implements Parser { SequenceParser(Collection\u0026lt;Parser\u0026gt; parsers) { ... } Collection\u0026lt;Node\u0026gt; parse(Stream stream) { ... } } // Parses if the stream satisfies multiple parsers and returns // the concatenation of all those parser results class AnyOfParser implements Parser { AnyOfParser(Collection\u0026lt;Parser\u0026gt; parsers) { ... } Collection\u0026lt;Node\u0026gt; parse(Stream stream) { ... } } // Usage: compose to build a larger parser Parser myParser = new SequenceParser( new AnyOfParser( new TextParser(\u0026#34;Hello\u0026#34;), new TextParser(\u0026#34;Goodbye\u0026#34;) ), new TextParser(\u0026#34; Jeff\u0026#34;) ) // this parser accepts: \u0026#34;Hello Jeff\u0026#34; or \u0026#34;Goodbye Jeff\u0026#34; myParser.parse(...); myParser may look weird, but it\u0026rsquo;s now easier to adapt to new requirements based on what we have. Changing the parser to parse 10 digits can be done without having to write a new class that implements Parser.\nWhich abstraction should I use? Both. The combination of both of these patterns that can make your software adaptable.\nImplementation-hiding abstractions are great for removing interactions with third party APIs from the rest of your code. Replacing or multiplexing implementations is easier. Use this for managing code you don\u0026rsquo;t control. Composable abstractions are great for expanding the flexibility of your own code. It\u0026rsquo;s great for adapting to change. Use this for code you do control that isn\u0026rsquo;t directly interfacing with code you don\u0026rsquo;t control. Using both is not new at all. Combining both gives you a style of architecting that may sound familiar for OO programmers: Hexagonal Architecture.\nAlternatively, others have called similar designs with different names:\nClean Architecture Functional Core, Imperative Shell Ports and Adapters If you pick up a classic TDD testing book, you\u0026rsquo;ll see it built with Use Cases. Use Cases are similar to Command Query Architecture (CQRS) [1]. which is becoming more popular because of Flux / ReactJS. They are similar in fundamentals with differing in details:\nAvoid code you don\u0026rsquo;t control from proliferating in your code base Compose together code you control as much as possible Hide the composition of your code behind a series of Use Cases. A composable solution exposes the complexity of the problem you\u0026rsquo;re solving that a Use Case can hide. Functional programming has similar architectures under the different names:\nInterpreter Pattern - Compose a solution that emits a sequence of commands that can be read by an abstract machine to do stateful work. Programs that produce bytecode is the most familiar example, but commands can also just be enums with associated data that can be switch-ed Functional Reactive Programming - Provide a mechanism of composition that is also a way to abstract input/output behavior in user interfaces. Functional programs tend to favor more composition, OO programs usually favor implementation hiding. While the mixture is debatable, it seems that both are necessary for well-designed programs.\n[1]: Despite Martin Fowler\u0026rsquo;s dislike of CQRS, I happen to find them valuable in conjunction with event sourcing. From personal experience, many long-lived applications usually build up a complicated domain beyond what a CRUD application can accomplish. Especially with cross-cutting concerns—authentication and authorization are usually the first two to come to mind. Add the ease of debugging an application from its event stream, and I feel the tradeoff of CQRS is worth its complexity if you event source your application\n","permalink":"http://localhost:1313/2016/20-two-kinds-of-abstractions.html","summary":"\u003cp\u003eWhen someone talks about abstractions, they\u0026rsquo;re usually trying to make the\nsoftware more flexible. But that\u0026rsquo;s usually one of two kinds of abstractions.\u003c/p\u003e\n\u003ch2 id=\"build-an-abstraction-to-_hide-an-implementation_\"\u003eBuild an abstraction to \u003cem\u003ehide an implementation\u003c/em\u003e\u003c/h2\u003e\n\u003cp\u003eAbstractions that hide implementations are more commonly touted as good designs.\n\u003ca href=\"https://github.com/lostisland/faraday\"\u003eRuby\u0026rsquo;s Faraday\u003c/a\u003e abstracts the specific HTTP library implementation.\nRails\u0026rsquo; \u003ca href=\"http://guides.rubyonrails.org/active_record_basics.html\"\u003eActiveRecord\u003c/a\u003e abstracts the SQL you need to write to\ninterface with a relational database. The\n\u003ca href=\"https://en.wikipedia.org/wiki/Data_mapper_pattern\"\u003eData Mapper Pattern\u003c/a\u003e abstracts the persistent storage from\nyour application.\u003c/p\u003e","title":"Two Kinds of Abstractions"},{"content":"What\u0026rsquo;s the best way to model a solution? In software, there\u0026rsquo;s several common ways of building solutions that solve specific problems. It\u0026rsquo;s worth trying to identify their characteristics and the tradeoffs they make.\nArchitect the Software After the Current Problem The easiest is way to model software. There\u0026rsquo;s no need to take in consideration of future solutions the user made want.\nSometimes this is what you need. If you\u0026rsquo;re writing a throw-away program, the fastest possible way to implement it is to codify for the exact problem you\u0026rsquo;re trying to solve. An example are most shell scripts. They tend to not be abstracted and usually automate a very specific task.\nIt\u0026rsquo;s a bit unfortunate that Object-Oriented Programming is generally taught as this way:\nclass Vehicle: def gas_consumed(self, velocity): return velocity class Car(Vehicle): pass # inherits from Vehicle class Truck(Vehicle): def gas_consumed(self, velocity): return velocity * 2 It\u0026rsquo;s a useful way to describe how classes work by using a mental schema that most people have in their heads. But this is more inflexible to actually adapt to changing requirements that software users always want.\nFor the example above, what if we want to model hybrid vehicles? Is it abstract like the Vehicle class? If it\u0026rsquo;s a concrete vehicle, then we need to make new classes for each kind of concrete vehicle we need (eg - HybridCar and HybridTruck).\nA feature like multiple inheritance can solve this problem to some degree, but it lacks the ability to remove features. For example, what if the Vehicle assumed that a car needs to be powered by gasoline? Our hybrid vehicle becomes harder to introduce.\nThis is same for shell scripts – most scripts will hardcode values and make assumptions to its execution environment.\nThese kinds of programs are cheaper to produce, but more expensive to change.\nArchitect the Software After the Hardware Another way to model software comes from its past, when computers were slower and more expensive. This design of software embraces the hardware it executes on – capable of efficiently executing on the platform. Embedded software, drivers, and video games tend to lean towards this model because of their performance sensitivity.\nSoftware tends to optimize for the efficiencies of computers. After algorithmic complexity, memory utilization ratio is common to measure. That is, how much of each block of memory fetched is utilized by the CPU. A nice (but a bit ranty) talk about this is Mike Acton\u0026rsquo;s Data Oriented Design talk.\nA more readily visible pattern is columnar storage over tabular storage patterns.\n# (Of course, python\u0026#39;s memory structure isn\u0026#39;t a direct mapping # as a language like c/c++, but we can pretend) # Tabular form, more conventional object-oriented pattern class Vehicle: def __init__(self, name, mpg, doors, miles, top_speed): self.name = name self.mpg = mpg self.doors = doors self.top_speed self.miles = miles # ... more fields ... vehicles = [Vehicle(...), Vehicle(...)] total_distance = 0 for vehicle in vehicles: total_distance += vehicle.mpg * vehicle.miles # Columnar form, only storage values that are needed together miles = [(mpg1, miles1), (mpg2, mile2), ...] total_distance = 0 for mpg, miles in vehicles: total_distance += mpg * miles Since the CPU fetches memory in chunks, we waste some of the memory fetch to the extra fields each vehicle has. This means more memory fetches. Looking at a latency chart, it\u0026rsquo;s easy to imagine many of these extra fetches adding up to a noticable additional time.\nNo doubt performance-centric designs sacrifice hardware abstractions. Most of this software couples to the exact hardware it executes on: a computer chip; or the kind of CPU architecture. Changing to another platform may waste all the effort put in to turning the execution performance.\nThese systems are also more expensive to build. They cater to the needs of the computer and optimize less for the readability of the programmer. A logical extreme to being performance-centric is to manually manage memory (probably using a custom memory allocator). And while it\u0026rsquo;s more efficient to execute on the machine, it comes at the cost of future flexibility.\nArchitect the Software After a Composable, Isolated Abstraction This is harder to describe.\nModeling software toward small abstractions avoids having the directly model either end. Instead, it\u0026rsquo;s road less traveled. Mostly because it\u0026rsquo;s a chicken-egg problem: a good abstraction requires a in-depth knowledge of the problem at hand; but the best way to know the problem well is to try and solve it multiple times.\nA great example of an abstraction is how many HTTP interfaces are defined: rack, wsgi, go/http\u0026rsquo;s Handler. They naturally provide the notion of middleware. Middleware can solve parts of what is needed to for an HTTP request:\nDivide work up by request (eg - URI routes, HTTP method, etc.) Perform authorization / authentication Automatically parse and emit specific data encodings (eg - JSON, XML, etc.) While middleware is generally focused toward solving HTTP, there\u0026rsquo;s no reason why you can\u0026rsquo;t use it to also solve your business domain.\nThe goal for composable abstractions is to maximize flexibility. They can suffer performance if it\u0026rsquo;s not considered. But more importantly, these little composable pieces are more complicated to understand at first. There\u0026rsquo;s a rampup cost for newcomers. That\u0026rsquo;s because a highly composable abstraction is a domain-specific language that needs to be learned. They\u0026rsquo;re overkill for small problems.\nDisclaimers Apply, see Fine Print Of course it\u0026rsquo;s all a gradient. Although large-scale software tends to be some of each, in different proportions. Although larger systems can forego composable abstractions due to the number of developers involved.\n","permalink":"http://localhost:1313/2016/19-design-of-software-solutions.html","summary":"\u003cp\u003eWhat\u0026rsquo;s the best way to model a solution? In software, there\u0026rsquo;s several common\nways of building solutions that solve specific problems. It\u0026rsquo;s worth trying to\nidentify their characteristics and the tradeoffs they make.\u003c/p\u003e\n\u003ch2 id=\"architect-the-software-after-the-current-problem\"\u003eArchitect the Software After the Current Problem\u003c/h2\u003e\n\u003cp\u003eThe easiest is way to model software. There\u0026rsquo;s no need to take in consideration\nof future solutions the user made want.\u003c/p\u003e\n\u003cp\u003eSometimes this is what you need. If you\u0026rsquo;re writing a throw-away program, the\nfastest possible way to implement it is to codify for the exact problem you\u0026rsquo;re\ntrying to solve. An example are most shell scripts. They tend to not be\nabstracted and usually automate a very specific task.\u003c/p\u003e","title":"Design of Software Solutions"},{"content":"Background The problem seems simple: open, edit, and save text files. This can range from JSON files to source code like every other editor.\nTurns out, this is a relatively difficult problem. The rise of javascript text editors surfaces the performance problem of editing large text. It\u0026rsquo;s a non-trivial problem. There are several desirable characteristics that editors want:\nEditors need to optimize for edits. Having immediate feedback for changes is paramount to text editing. This includes editing large files. Editors need to optimize for reads. This is implied for optimized edits so that users can see immediate feedback to their edit. This also includes support for large files. Editors should minimize memory usage. Reduced overhead for storage of text leaves more memory for more text buffers. This is useful for developers editing multiple projects at once (eg - microservices). Different data structures support these requirements in varying degrees of success. For the sake of this article, I\u0026rsquo;m ignoring many other features editors usually have:\nSyntax highlighting Autocomplete Code Folding Onward!\nNaïve Solution The easiest way to solve this is to use your favorite programming language\u0026rsquo;s String type. This is usually analogous to a (resizable) array of characters:\n# python contents = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] # mutable # or contents = \u0026#39;abc\u0026#39; # mutable Arrays have great performance for reading any character. But making changes isn\u0026rsquo;t great.\nEditing the end of text is f\u0013ast: just by adding characters at the end of the buffer. Editing the middle of the text is not too fast: inserting characters first requires moving all characters after it off by the number of characters being added. Editing the beginning of the text is the worst case: inserting characters requires shifting the entire text buffer. The performance characteristics can be shifted if you switch from a standard resizable array to a resizable circular buffer to allow fast inserts on either end. But there still poor performance in most the common case of editing in the middle of the text.\nArray of Strings The next level, is using an array of strings. It helps minimize the worst case by assuming that most lines are relatively small - less than 200 characters. This doesn\u0026rsquo;t fundamentally solve the problem:\nLarge single lines (eg - compressed JS / JSON) devolves into an array. Files with many lines exhibit performances problems when creating new lines. This is common for JavaScript editors. The performance impact of strings versus ArrayBuffer is unknown. The potential performance gains of ArrayBuffer may be negated by having character encoding and conversion being done all the time when reading and writing from the buffer.\nGap Buffer When the programming language supports direct manipulation of bytes, a common data structure is call the Gap Buffer. It\u0026rsquo;s simply an array with a \u0026ldquo;gap\u0026rdquo; of free space that\u0026rsquo;s used to allow efficient edits that are close to each other. The gap is moved to the desired location by shifting characters. Since moving the gap buffer is the most expensive, it is generally only done when an edit is needed to be performed.\n# python gap_size = 3 # field to track the size of the gap gap_start = 2 # field to track the location of the gap buffer = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, None, None, None, \u0026#39;c\u0026#39;] # ^ \u0026#34;Gap\u0026#34; ^ The gap moves to where edits are being made. This is done by shifting the characters to either side of the buffer. The follow examples demonstrate how basic operations behave.\nMoving to the Beginning # before: buffer = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, None, None, None, \u0026#39;c\u0026#39;] # after gap_size = 3 gap_start = 0 buffer = [None, None, None, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] Inserting \u0026rsquo;d' # before: buffer = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, None, None, None, \u0026#39;c\u0026#39;] # after gap_size = 2 gap_start = 3 buffer = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;d\u0026#39;, None, None, \u0026#39;c\u0026#39;] Deleting \u0026lsquo;b\u0026rsquo; # before: buffer = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, None, None, None, \u0026#39;c\u0026#39;] # after gap_size = 4 gap_start = 1 buffer = [\u0026#39;a\u0026#39;, None, None, None, None, \u0026#39;c\u0026#39;] Some famous text editors utilize the Gap Buffer as their preferred storage mechanism, such as Emacs. Unlike how I\u0026rsquo;ve demonstrated the examples above, implementation commonly backed by a circular buffer where the gap is the edges of the array. Think of it as \u0026ldquo;inverting\u0026rdquo; the storage representation of an array of characters using a circular buffer.\nIt\u0026rsquo;s reasonably efficient assuming your files also don\u0026rsquo;t get too large. While gap buffers can generally handle much larger files (because edits aren\u0026rsquo;t usually all over the place), they tend to still perform poorly on extremely large files in a find-replace use case.\nReferences Here\u0026rsquo;s a list of editors and their storage mechanisms:\nAtom uses Array of Strings Visual Studio Code uses Array of Strings Brackets uses Array of Strings via CodeMirror Vim represents text as an Array of Strings using an internal tree data structure, similar to Rope, but leaf nodes holding lines when possible. Emacs uses Gap Buffers. Eclipse uses Gap Buffers. Other Data Structures that need to be elaborated on:\nRopes (or other tree data structures) Piece table (preferred by many commercial \u0026ldquo;editors\u0026rdquo; like Word). Comments, questions, corrections? Tweet me at @jeffhui.\n","permalink":"http://localhost:1313/2016/18-editing-text-basics/","summary":"\u003ch1 id=\"background\"\u003eBackground\u003c/h1\u003e\n\u003cp\u003eThe problem seems simple: open, edit, and save text files. This can range from\nJSON files to source code like every other editor.\u003c/p\u003e\n\u003cp\u003eTurns out, this is a relatively difficult problem. The rise of\n\u003ca href=\"https://atom.io\" title=\"Github Atom\"\u003ejavascript\u003c/a\u003e \u003ca href=\"https://code.visualstudio.com/\" title=\"Microsoft Visual Studio Code\"\u003etext\u003c/a\u003e \u003ca href=\"http://brackets.io/\" title=\"Adobe Brackets\"\u003eeditors\u003c/a\u003e surfaces the performance\nproblem of editing large text. It\u0026rsquo;s a non-trivial problem. There are several\ndesirable characteristics that editors want:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEditors need to \u003cstrong\u003eoptimize for edits\u003c/strong\u003e. Having immediate feedback for changes\nis paramount to text editing. This includes editing large files.\u003c/li\u003e\n\u003cli\u003eEditors need to \u003cstrong\u003eoptimize for reads\u003c/strong\u003e. This is implied for optimized edits so\nthat users can see immediate feedback to their edit. This also includes\nsupport for large files.\u003c/li\u003e\n\u003cli\u003eEditors should \u003cstrong\u003eminimize memory usage\u003c/strong\u003e. Reduced overhead for storage of text\nleaves more memory for more text buffers. This is useful for developers\nediting multiple projects at once (eg - microservices).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDifferent data structures support these requirements in varying degrees of\nsuccess. For the sake of this article, I\u0026rsquo;m ignoring many other features editors\nusually have:\u003c/p\u003e","title":"Editing Text (Basics)"},{"content":"The more you learn, the more this skill seems to be necessary. When missing a bug or a refactor opportunity, I wonder how did I miss this? Sure, everyone wants to learn from their mistakes. But noticing the little details gives you the opportunity to adapt. Massive function definitions starts off looking like an common pattern for code that needs to be refactored. Those dozen one-letter variables names probably should be better named. Shadowing a variable is prone to introduce errors in the future. All those mental notes form from being able to observe it.\nBy observing, I mean decerning the signal from the noise of inputs. And it doesn\u0026rsquo;t have to apply to programming. How can you make your food taste better? The video game, Braid, is a great example. It teaches players how its rules of time manipulation lead to certain implications that are required to solve puzzles.\nObservation an interesting commonality among many skills. Jiro remarks how he could be a better chef if only he had the tasting ability of Joel Robuchon. Breaking a bad habbit first requires noticing that it\u0026rsquo;s a bad habbit in the first place. The first step to addiction is noticing (and admitting) you have a problem. Great designers try to solve for the sutle details of human interaction with the products they build.\nOr another way of describing an expert: a person who has refined observation for a specific skill. Someone that\u0026rsquo;s a jack-of-all-trades is observant at seeing similarities across multiple specialties. A researcher is looking for new observations.\nHow do you become more observant? I\u0026rsquo;m not sure. There\u0026rsquo;s a lot of little ways to experience more:\nMeditation focuses on watching your breathing instead of wandering your mind. Hiking or climbing focuses on you physical movement. Drawing focuses on replicating details of the subject being drawn. Write in a journal (eg - food journal, finance journale). Taking up professional photography. Playing video games Standup Comedy Sports Etc. They seems to have one thing in common: they all require noticing a sensory experience. It\u0026rsquo;s not just performing one of these activities, but getting skilled at it makes you more observant.\n","permalink":"http://localhost:1313/2016/17-observation.html","summary":"\u003cp\u003eThe more you learn, the more this skill seems to be necessary. When missing a\nbug or a refactor opportunity, I wonder how did I miss this? Sure, everyone\nwants to learn from their mistakes. But noticing the little details gives you\nthe opportunity to adapt. Massive function definitions starts off looking like\nan common pattern for code that needs to be refactored. Those dozen one-letter\nvariables names probably should be better named. Shadowing a variable is prone\nto introduce errors in the future. All those mental notes form from being able\nto observe it.\u003c/p\u003e","title":"Observation"},{"content":"Let\u0026rsquo;s mentally build an API for an an e-commerce site. Let\u0026rsquo;s say we\u0026rsquo;re tasked with building the cart \u0026amp; checkout portion of the API. Building a RESTful API seems like the natural choice. At first, a Cart seems like any other model entity in the system. But what about an multi-page checkout step?\nAllow partial updating of the Cart model (sounds like a job for PATCH). We need to preserve as much information as possible on the server to allow the user to pick up where they left off. Each update needs to be validated against the current known state of the world. Store credit may not fully cover an order that has an upgraded shipping method specified later on. The final cart has to be \u0026ldquo;commited\u0026rdquo; where final validations need to be performed before commited. An finally, the committed cart requires taking to third party APIs all along the way (shipping, credit card processing, tax calculations) as well as at the commit point. REST doesn\u0026rsquo;t provide an easy way to model this.\nWe could add new custom endpoints, but that means this entity is no longer following REST.\nAnother olution is the use new intermediary REST entities for each step of checkout. But that\u0026rsquo;s weird. Each model only be useful for that step of the checkout. Not including the fact that we would need to know how to retrive the intermediary model or unify the identifiers.\nOur REST hammer isn\u0026rsquo;t going to cut it. It\u0026rsquo;s just not a general enough abstraction to use all network communications.\nWhat went wrong? The abstraction, REST, didn\u0026rsquo;t account for something in our problem domain. Domain modeling is half of what makes good abstractions. And that\u0026rsquo;s anything but easy.\nA poor abstraction is a misunderstanding of the problem. The original problem it ment to solve is fundamentally incorrect. Creating abstractions without initial contact with the problem usually births these abominations.\nA mediocre abstraction is leaky. That means it doesn\u0026rsquo;t account for unforseen situations. Special cases and work-around code are common symptoms. First-level refactors tend to be this level inside applications. It\u0026rsquo;s perfectly acceptable for frontend applications to have this level of abstraction. They only need to solve the solution for the specific context in mind and not future situations.\nA decent abstraction solves the problem well, but doesn\u0026rsquo;t factor in expanding scope. It doesn\u0026rsquo;t provide an obviously pattern to apply or extension point. Lots of libraries start like this. Many libraries fall into this category. And it\u0026rsquo;s fine if the scope they\u0026rsquo;re solving is a finite problem, such as implementing a specification. Something like REST would be here. But solving a general problem needs to go further.\nA great abstraction solves the problem well with considerations for unaccounted scope. It does provide a pattern to apply or an extension point for new capabilities. The difficulty in reaching this level as a general purpose library is rare and difficult.\nIn short, great abstractions is far from implementation details but close enough to model the problem at hand. That\u0026rsquo;s not easy.\nProgrammatic abstractions minimize the surface area between both sides of the interface. A good example is go\u0026rsquo;s http interface to its web server:\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } type ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(int) // Status Code } type Request struct { Method string URL *url.URL Header Header Body io.ReadCloser ContentLength int64 // ... more fields ... } Go\u0026rsquo;s http interface is similar to Python\u0026rsquo;s WSGI or Ruby\u0026rsquo;s Rack interfaces. The surface area is a function Handler.ServeHTTP for the http server and ResponseWriter delegate methods for the app to tell the server how to behave. The streaming writer is intentional, as it\u0026rsquo;s possible to build a buffered / functional-like interface on top of a streaming one. Programmatic interfaces should have a small surface area. That\u0026rsquo;s one of the main arguments of GraphQL over REST: there are no ad-hoc endpoints for the client to know about.\nThat\u0026rsquo;s not to saying that class-based modeling of problem domain is wrong. For example, Joda-time is abstracting the complex, inconsistent rules of time that makes it hard to abstract in a clean, concise interface. Abstracting time is fundamentally difficult (and ever changing) problem. At worst, these libraries tend to inform incorrect or ambigious usages.\nWe should minimize introducing human complexity and prefer programmatic ones. Obviously that can\u0026rsquo;t apply universally - user interfaces and business rules will likely need some of that complexity. But both areas generally don\u0026rsquo;t need highly factored code.\n","permalink":"http://localhost:1313/2016/16-domain-modeling/","summary":"\u003cp\u003eLet\u0026rsquo;s mentally build an API for an an e-commerce site. Let\u0026rsquo;s say we\u0026rsquo;re tasked\nwith building the cart \u0026amp; checkout portion of the API. Building a RESTful API\nseems like the natural choice. At first, a Cart seems like any other model\nentity in the system. But what about an multi-page checkout step?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAllow partial updating of the Cart model (sounds like a job for PATCH). We\nneed to preserve as much information as possible on the server to allow the\nuser to pick up where they left off.\u003c/li\u003e\n\u003cli\u003eEach update needs to be validated against the current known state of the\nworld. Store credit may not fully cover an order that has an upgraded shipping\nmethod specified later on.\u003c/li\u003e\n\u003cli\u003eThe final cart has to be \u0026ldquo;commited\u0026rdquo; where final validations need to be\nperformed before commited.\u003c/li\u003e\n\u003cli\u003eAn finally, the committed cart requires taking to third party APIs all along\nthe way (shipping, credit card processing, tax calculations) as well as at the\ncommit point.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eREST doesn\u0026rsquo;t provide an easy way to model this.\u003c/p\u003e","title":"Modeling the Domain"},{"content":"Instead of sounding prescriptive, this article is much more descriptive.\nI\u0026rsquo;m describing my regular workflows: what is working; what isn\u0026rsquo;t working. I\u0026rsquo;m documenting this for completely selfish reasons since it\u0026rsquo;s useful to track progression (if any). It happens to be a great inflection point since a recent illness has thrown me off my routine in the past week.\nLike most people, there\u0026rsquo;s a need to regularly do:\nRespond to messages (twitter, facebook, texts) Respond to mail (physical, email) Attend events (birthdays, social gatherings, meetups) Capture ideas (they tend to come up in the most random places) Living (rent, bills, taxes, laundry, cleaning) All while (attempting) to achieve other goals:\nPersonal (eg - Open Source) Projects Work / Career Learning (Re)formation of Habbits The problem is balancing between them all. I\u0026rsquo;ve been trying a series of techniques over the few years, but rarely checked-in and reflected. I want to increase this \u0026ldquo;check-in\u0026rdquo; frequency to be less than a couple years. But let\u0026rsquo;s review how they\u0026rsquo;ve been.\nThe Keep Defer non-emergency messages \u0026amp; mail to specific times (usually during or after commutes). This is an okay result. It\u0026rsquo;s great at freeing my time at the potential (social) cost of not responding quickly. This partially results from my time at Pivotal, where it\u0026rsquo;s less compulsive to check these sources. In a weird turn of events, I happen to use e-mail as a way to avoid having an rss feed (for news \u0026amp; github issues). While those notifications greatly increase the time to process my inbox (from 30 daily messages to 200+), it also discourages the likelihood of randomly checking my mail. And that\u0026rsquo;s something I like.\nIt might be unfortunate that twitter, facebook, text messages, and phone calls happen to fall into this deferred group too. I still feel weird not answering phone calls or text messages, because I\u0026rsquo;ll inevitably forget about it. I\u0026rsquo;m not sure what\u0026rsquo;s the best balance to strike there.\nAutomate what\u0026rsquo;s possible. What I\u0026rsquo;ve automated has been great. Unfortunately, that\u0026rsquo;s not much:\nAutopay rent and bills Auto-transfer retirement investments Use software like Turbotax to fill out taxes in a couple hours at most. Recurring calendar events for laundry / cleaning (weird, but works surprisingly well). Automate deploys Cutting new releases of Quick \u0026amp; Nimble has been a huge time saver with less errors (I still can\u0026rsquo;t get the release notes 100% yet). Fully automating the deployment of YACS has saved countless hours. It\u0026rsquo;s the gift that keeps on giving. CI is valuable to merge pull requests via my phone when it\u0026rsquo;s working. Travis \u0026amp; CircleCI have not been the best at keeping up to date though. Also, cooking 4-5 times per week is way better than zero! :)\nThe Watch Inboxing items has been invaluable. I tend to get tasks in a form I\u0026rsquo;m ready to process:\nSend a reminder to me as an email so I can create a calendar event later. (You can guess I\u0026rsquo;m an inbox zero fan.) File an issue instead of just telling me, because I can\u0026rsquo;t possibly remember that. Using a derivation of the bullet journal. More on that below. The bullet journal is about organizing tasks into monthly, daily tasks with room to take free-form notes. It\u0026rsquo;s basic layout is as follows:\nThe first few pages are an index to quickly jump to pages (which are numbered). The next couple pages are for tasks for months in the future (aka - tasks to do later). Each \u0026ldquo;section\u0026rdquo; starts with a monthly calendar on a task list Every day is a \u0026ldquo;daily\u0026rdquo; log entry containing a bulleted list: tasks (dots) events (circles) notes (bullet points) You can then transfer tasks to each month as follows: X out the dot if it\u0026rsquo;s been completed \u0026gt; the dot if the task is deferred to next month \u0026lt; the dot if the task is deferred to more than a month later Every month, move all the deferred tasks to their appropriate locations. Feel free to use the next available page as free-form notes and mark the page number in your index. I have been doing a subset of this that involves only a daily log entries and indexes. I\u0026rsquo;ll continue to expand to more of the full bullet journal over time. This analog form has been a lot better than most digital forms. I use a A6 notebook which is about the size of an iPhone 6+\nThe main problem is that there are still too many inboxes. I haven\u0026rsquo;t been great at processing them all.\nAt work, Tracker is this inbox list. It feels like a conflict between this and the bullet journal. Calendar events are separate from my bullet journal and cut into perceived time to complete tasks. Github issues are fragmented into an inbox per project. They\u0026rsquo;re duplicated into my email inbox to ensure I don\u0026rsquo;t miss them, but I still happen to. Also, github does not provide any useful tools for organizing the issues and pull requests.\nI need to unify the inbox. I\u0026rsquo;ll attempt to use the bullet journal as the primary inbox with my mailbox as the review to other\u0026rsquo;s requests.\nThe Change All this organizing tends to let me cut up my tasks into smaller chunks that what\u0026rsquo;s needed for large tasks. It allows me to respond consistently, but discourages allocating full-day tasks \u0026ndash; such as a CLI-only Quick implementation, or rewriting Fox into Swift.\nThis severely has cut into my long-term tasks and goals. There\u0026rsquo;s an ideal to record screencasts that has been lavishing for months. I need to fully dedicate a day or two in a month to work on these tasks. Similar to other habits: daily exercising and avoiding nail biting.\nActions What should change?\nUse bullet journal as the primary \u0026ldquo;inbox\u0026rdquo; Add tasks to check other inboxes Allow allocation of all-day tasks to a weekend Side projects Screencasts Reading Learning Increase the frequency time slots for messages \u0026amp; mail activities Perhaps 3 - 4 / day instead of just 1 - 2 / day ","permalink":"http://localhost:1313/2015/15-daily-processes.html","summary":"\u003cp\u003e\u003cem\u003eInstead of sounding prescriptive, this article is much more descriptive.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m describing my regular workflows: what is working; what isn\u0026rsquo;t working. I\u0026rsquo;m\ndocumenting this for completely selfish reasons since it\u0026rsquo;s useful to track\nprogression (if any). It happens to be a great inflection point since a recent\nillness has thrown me off my routine in the past week.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eLike most people, there\u0026rsquo;s a need to regularly do:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRespond to messages (twitter, facebook, texts)\u003c/li\u003e\n\u003cli\u003eRespond to mail (physical, email)\u003c/li\u003e\n\u003cli\u003eAttend events (birthdays, social gatherings, meetups)\u003c/li\u003e\n\u003cli\u003eCapture ideas (they tend to come up in the most random places)\u003c/li\u003e\n\u003cli\u003eLiving (rent, bills, taxes, laundry, cleaning)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll while (attempting) to achieve other goals:\u003c/p\u003e","title":"Daily Processes Check-In"},{"content":"People always ask about how did you learn this or work so quickly doing that? It\u0026rsquo;s a tough question to answer elegantly. And it\u0026rsquo;s a cop-out to vaguely say I spent my free time looking into that particular topic. It\u0026rsquo;s a socially-acceptable excuse.\nBut no doubt that this requires time. The time spent learning comes from somewhere, since we all only have 24 hours in a day for this. In our field, there\u0026rsquo;s always time you must dedicate to learning to keep up to date.\nTo be blunt: there\u0026rsquo;s certain things you can acquire on the job - incremental learnings. But for significant advancements in your thought and tooling, you\u0026rsquo;ll need to allocate a non-trival amount of time for it (hats off to you if your job can offer you that kind of personal investment).\nLearning something completely foreign requires significant time to dedicate. It\u0026rsquo;s going to be painfully slow in comparison to what you\u0026rsquo;re familiar with. Learning vim or emacs for the first time will be extremely painful if you haven\u0026rsquo;t tried those editors before. It\u0026rsquo;ll feel like a child trying to walk for the first time. It\u0026rsquo;s going to feel terribly unproductive. And that\u0026rsquo;s OK. There\u0026rsquo;s a valley of learning you need to overcome first before you can regain or surpass your previous productivity.\nWhile I personally believe that emacs and vim improve editing of text for specific use cases (and not generally improved editing). It\u0026rsquo;s mostly a net-loss for just text editing. But it can benefit beyond just those editors.\nFor example, vim and emacs keybindings are ported to other systems beyond editing source code. There\u0026rsquo;s vim browser extensions that add vim-like navigation to your browser. There\u0026rsquo;s XVim for vim keybindings in Xcode. OS X comes with some emacs keybindings for all native text editing controls (including Xcode).\nBut this applies to more than just emacs and vim. What about Prolog, Clojure, and Haskell? They all provide different ways of viewing the world.\nFrom the smallest skills to largest theories, they require investment:\nTyping faster Learning hotkeys / shortcuts Functional programming Distributed systems Testing Databases Using App Code It\u0026rsquo;s not magical genius inherited ability. Just lots of time. And learning a bit about various topics adds up. Because going faster requires going slow first.\n","permalink":"http://localhost:1313/2015/14-going-fast-by-going-slow.html","summary":"\u003cp\u003ePeople always ask about how did you learn this or work so quickly doing that?\nIt\u0026rsquo;s a tough question to answer elegantly. And it\u0026rsquo;s a cop-out to vaguely say I\nspent my free time looking into that particular topic. It\u0026rsquo;s a\nsocially-acceptable excuse.\u003c/p\u003e\n\u003cp\u003eBut no doubt that this requires time. The time spent learning comes from\nsomewhere, since we all only have 24 hours in a day for this. In our field,\nthere\u0026rsquo;s always time you must dedicate to learning to keep up to date.\u003c/p\u003e","title":"Going Fast by Going Slow"},{"content":"There\u0026rsquo;s a process behind every result.\nIf you say, \u0026ldquo;we have no process, there\u0026rsquo;s no meetings\u0026rdquo;, then that\u0026rsquo;s your process. Admitting to no process simply indicates that you don\u0026rsquo;t have it formalized. A poorly defined process hurts. Processes enable efficiency and consistency. They can also act like a communication protocol among team members, teams, and organizations. Process can improve your quality.\nLet\u0026rsquo;s think about how you deploy an application. What does that process look like? A poorly defined deployment process is inconsistent – something undesirable for a deployment. At minimum, a quick checklist works:\nSSH into box Copy application files to box Kill old processes Start new processes Check site is up That\u0026rsquo;s clearer, but far from perfect. We can refine it with more detail:\nSSH into box SSH to app server: ssh root@instance1.example.com Copy application files to /www/deploy/my-app tar -czf app.tar.gz /local/application scp app.tar.gz instance1.example.com:app.tar.gz ssh tar -xzf app.tar.gz rm -rf /www/deploy/my-app mv app /www/deploy/my-app Kill old processes view processes: ps aux | grep myapp kill processes: kill -9 app-pid Start new processes: /www/deploy/my-app/bin/myapp Check site is online: www.example.com Obviously you can make this more detailed1. Checklists are used everywhere, from flying planes to surgery. This formalization reduces errors: an 18% reduction in mortality in surgeries with checklists according to a Veterans Affairs study. Not bad for a process that\u0026rsquo;s just a list actions on a piece of paper.\nBut a checklist is a straight-jacket. It\u0026rsquo;s more restrictive. You\u0026rsquo;ll need decipline to avoid the temptation to stray from the checklist. In software, the logical conclusion is to fully automate it, but we can\u0026rsquo;t automate everything in the real world.\nIt\u0026rsquo;s important to distinguish that not every process is great a process. But great processes usually provide the following:\nConsistency: Clear direction to achieve a goal ensuring smaller goals are met along the way. Adaptability: Provides self-reflection to allow the process to change for new situations. Shareability: Processes that can be communicated to others to more easily achieve consistency. The checklist meets all three at a basic level: it\u0026rsquo;s a reminder of actions to take to solve a larger goal; a checklist can be change while not running through it; and it can be given to another person to use, copy, or follow.\nIt\u0026rsquo;s interesting to see other teams\u0026rsquo; processes. NASA\u0026rsquo;s space shuttle software process is nearly opposite to many startups:\nPsudeo-code specifications \u0026amp; discussions defining implementation, behavior, and impact to code - avoids code silos 9-5 work hours Individual contributors focus on quality: Coders \u0026amp; Verifiers compete to improve quality Large commit messages with full history of discussion \u0026ldquo;People have to channel their creativity into changing the process, not changing the software\u0026rdquo; Reduced error rates by 90%, but has an annual budget of $35 million Or consider an agile company2, I\u0026rsquo;m taking roughly Pivotal Labs\u0026rsquo;s:\nIteration Planning Meeting: review of future work - implementation and behavior Pair programming - avoids code silos 9-5 work hours Individual contributors focus on quality Retrospectives to adapt and improve the process Tracker provides history of decisions and plan future development Looks a little bit similar?3 Like checklists, they\u0026rsquo;re making tradeoffs - they cost more in the short-term but produce better results in the long run. I\u0026rsquo;m not saying these examples are perfect, but they\u0026rsquo;re defined, sustainable and structured. But working 80 hours a week to optimize every line of code for performance is a different kind of process that doesn\u0026rsquo;t seem as sustainable or productive.\nOpen source projects are no different. They function better with processes in place. What is are your guidelines to good pull requests? What is your process for cutting releases? Is there a process for handling security disclosures? Besides helping new core team members on the project, they reduce the likelihood of making mistakes.\nSo what does your process look like? We know there\u0026rsquo;s always one.\n","permalink":"http://localhost:1313/2015/13-Process-is-King.html","summary":"\u003cp\u003eThere\u0026rsquo;s a process behind every result.\u003c/p\u003e\n\u003cp\u003eIf you say, \u0026ldquo;we have no process, there\u0026rsquo;s no meetings\u0026rdquo;, then that\u0026rsquo;s your process.\nAdmitting to no process simply indicates that you don\u0026rsquo;t have it formalized. A\npoorly defined process hurts. Processes enable efficiency and consistency. They\ncan also act like a communication protocol among team members, teams, and\norganizations. Process can improve your quality.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s think about how you deploy an application. What does that process look\nlike? A poorly defined deployment process is inconsistent – something\nundesirable for a deployment. At minimum, a quick checklist works:\u003c/p\u003e","title":"Process is King"},{"content":"As an engineer, one of the most valuable skills you can have is to communicate effectively. This applies both to your follow engineers as well as non-engineers (PMs, designers, business). Obviously, this advice is generally applicable, but many engineers don\u0026rsquo;t craft their communication to the business well. Common problems are:\nTalking too much about technical implementation. Talking too little about technical implementation. Too much technical implementation drowns out the important details that businesses are concerned about. It drags on discussions and meetings unnecessarily. Imagine if a designer talked for hours about how they picked the correct border radius value and color for their buttons in a meeting. That\u0026rsquo;s a waste of time for business stakeholders and engineers in that meeting. Getting far into the weeds like that quickly wastes discussions or meetings1.\nSimilar to spewing technical details, using fancy words are also detrimental to your goal of effective communication. If your collaborators aren\u0026rsquo;t on the same page with your definition, then you\u0026rsquo;re introducing more error for the worst kinds of mistakes. They can range from not being explicit on the units of measurement; not being aligned what functional programming is; or why engineering should use a new tool. These undefined words are assumptions. And assumptions are the enemy of clear communication. It\u0026rsquo;s assumptions that exaggerate mistakes.\nIn comparison, hiding too much of the the technical implementation can also be detrimental. You\u0026rsquo;re denying the business from potentially making important decisions. Similar to why the waterfall model is flawed: it assumes each step has perfect information to operate in isolation. But no one in the company has the complete problem in their head to completely solve the solution for the customer2. A company hires experts (designers, product managers, engineers, marketers, etc.) to provide information and action into the decision-making process. Making decisions is the core of a business\u0026rsquo; operation. It\u0026rsquo;s what executives and managers, including PMs, do all day. They rely on others to extract the signal from the noise and to execute on those decisions.\nExperts provide both information and execution. Sure you can implement your software solution, but without providing the business the information why it\u0026rsquo;s valuable, there\u0026rsquo;s no reason to fund or support that project from an stakeholder\u0026rsquo;s perspective. A solution may become a waste of time if it\u0026rsquo;s not solving the problem for the demographic the business is targeting, for example. This scales from the which projects to sponsor to if a bug should be fixed instead of that new feature marketing wants.\nIt\u0026rsquo;s not uncommon for engineers over optimize3 or choose experimental technologies4 without consulting the business for feedback. That\u0026rsquo;s keeping the business in the dark about the implications for those decisions. Every decision has tradeoffs.\nWhat\u0026rsquo;s the right amount then? So what\u0026rsquo;s the right amount of technical implementation to talk about to a non-technical person? It\u0026rsquo;s the wrong question. You actually want to talk in terms of technical implications.\nThe company needs to understand the tradeoffs for the technical decisions you\u0026rsquo;re proposing. Saying you\u0026rsquo;re using the latest NoSQL database because of its marketed performance also comes with a lot of unknowns. How do you know it reliably preserves the data your store? How difficult is it to maintain operationally?\nEdn seems like a great serialization format if you\u0026rsquo;re using Clojure and ClojureScript now. Sure it didn\u0026rsquo;t seem like a decision the business needed to care about, but there are implications for that. Edn effectively locks-in your ability to move off of a Clojure stack in the future. While JSON is inferrior in capabilities, it keeps that option open. Alternatively, you can maintain both JSON and Edn serializations, but that increases your surface error to maintain. In this example, it\u0026rsquo;s easy to infer the correct business decision, but if you\u0026rsquo;re not sure, that needs to be presented to the business as choices with clear impacts to the business in a variety of future scenarios.\nSure, you don\u0026rsquo;t raise every little problem to the business, that\u0026rsquo;s where your expertise comes in. You need to know when the scope of the decision extends beyond your domain and into others. You decide which technical discussions they need to participate and which they don\u0026rsquo;t. There\u0026rsquo;s always a tradeoff for every decision you make.\nYou\u0026rsquo;re the bridge from your expertise to the business5.\nDepending on the context, using Cloud Formation may be a technical implementation or a technical implication. Keeping aligned with the business\u0026rsquo; goals is important to know when to present the decision. Not all big decisions are blocking, especially when technologies can be easily swapped (e.g. - swapping SQL databases may be relatively easy to switch) after the organization determines which to use.\nWhile talking up the chain of command important for determining impact, daily discussions on your team is primarily about course-correcting. The team needs to communicate to find and resolve errors before they devolve into major problems. Therefore, the team\u0026rsquo;s communication should avoid ambiguities. Avoid terms unfamiliar with your collaborators and clear any confusion as early as possible to keep mistakes6 small. Use a shared vocabulary that is explicitly agreed upon to be concise. Avoid introducing terms arbitrarily simply because you read it up on a blog. New team members should be given the list of agreed upon words and their definition (aka, domain knowledge).\nThe context of efficient team communication could be its own article. But suffice to say that you want to remove any confusion and provide quick feedback to detect any problems. Listen after you explain a concept to your team members. Is it possible to derive different meaning to what you\u0026rsquo;re saying? Does the person look a little confused? Are they unwilling to ask the question because they feel it\u0026rsquo;s silly or stupid?\nTalking to someone is similar to writing, it\u0026rsquo;s best to anticipate the journey in their thoughts to effectively guide someone to understanding your thoughts. But unlike writing, you have more feedback to what you\u0026rsquo;re saying. Take advantage of that extra information.\nAnd this varies from day-to-day. Sometimes it feels like everyone\u0026rsquo;s on the same page, while others days feel like non-stop back-and-forth. But that\u0026rsquo;s collaboration in action: a never-ending effort to piece together the sub-problems to provide a more comprehensive solution. It\u0026rsquo;s how the sum becomes greater than its parts.\n","permalink":"http://localhost:1313/2015/12-communicating-as-an-engineer.html","summary":"\u003cp\u003eAs an engineer, one of the most valuable skills you can have is to communicate\neffectively. This applies both to your follow engineers as well as non-engineers\n(PMs, designers, business). Obviously, this advice is generally applicable, but\nmany engineers don\u0026rsquo;t craft their communication to the business well. Common\nproblems are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTalking \u003cem\u003etoo much\u003c/em\u003e about technical implementation.\u003c/li\u003e\n\u003cli\u003eTalking \u003cem\u003etoo little\u003c/em\u003e about technical implementation.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eToo much technical implementation drowns out the important details that\nbusinesses are concerned about. It drags on discussions and meetings\nunnecessarily. Imagine if a designer talked for hours about how they picked the\ncorrect border radius value and color for their buttons in a meeting. That\u0026rsquo;s a\nwaste of time for business stakeholders and engineers in that meeting. Getting\nfar into the weeds like that quickly wastes discussions or\nmeetings\u003c!-- raw HTML omitted --\u003e\u003c!-- raw HTML omitted --\u003e1\u003c!-- raw HTML omitted --\u003e\u003c!-- raw HTML omitted --\u003e.\u003c/p\u003e","title":"Communicating as an Engineer"},{"content":"It is difficult to always be improving in the software industry. In creative fields, many artists talk about churn. When starting out, there\u0026rsquo;s an enormous amount of work to produce to get better. If you\u0026rsquo;re new, there\u0026rsquo;s a massive amount of bad code you need to write. That\u0026rsquo;s OK, it\u0026rsquo;s necessary. But the rate of improvement decays as time progresses. As your notoriety grows, you can no longer just crank out code to get better, how can you preserve some rate of improvement? It feels like the rate of learning looks like this:\nWhy does it go down? We can speculate. Old information conflicts with newer information. Experienced engineers get promoted beyond the engineering and their knowledge goes stale. How does an experienced individual get technically stronger? Let\u0026rsquo;s throw a few ideas:\nExplore related fields Study more in depth the current field Teach what you know These strategies provide a different kind of \u0026ldquo;churn\u0026rdquo;. They look less like the traditional work of programming, but they provide more leverage, prestige, and challenges. It\u0026rsquo;s not too different from management.\nThe benefits of exploring existing, related fields is obvious: the expert becomes a beginner again. A beginner\u0026rsquo;s mind reopens vulnerability that experts have long eliminated, and too many avoid. Different experiences provide different perspectives to your craft. It\u0026rsquo;s why diverse teams are better than mono-cultured ones. An example is artificial intelligence, where most of the successful algorithms are based on neuroscience. That doesn\u0026rsquo;t preclude you from working in your current field, but it\u0026rsquo;s a way to curate ideas and techniques you wouldn\u0026rsquo;t otherwise have.\nWhile exploring other fields is much easier to learn a breath of information. Narrowing solidifies the knowledge already known. It\u0026rsquo;s similar to starting out as a civil engineer before learning physics. The engineering brings practical experience to theory. It provides intuition to theoretical concepts. This fills gaps in your knowledge both in known boundaries and unexplored territories. It\u0026rsquo;s a two-way street, as theory is also improved through practice. Personally, this deep dive creates an exciting dilemma: we know so little in most areas. This is both good and bad. Bad since we have so little concrete knowledge. Good since it\u0026rsquo;s easy to contribute to the pool of human knowledge. This much applies to every industry, for every specialty. It doesn\u0026rsquo;t take long to get to the edge of human knowledge in one particular field.\nLast, but not least, teaching is another form of learning. Learning something gives you a unique opportunity to do one thing: explain what was the tipping point to make you understand something in the first place. Teaching is one of the best ways to capture fleeting knowledge. That\u0026rsquo;s why I\u0026rsquo;m happy to work with newcomers - they\u0026rsquo;re sometimes more helpful to me than I am to them. Like debaters that forge their arguments in battle, I\u0026rsquo;ve sharpened my thought by explaining my ideas to others. It\u0026rsquo;s far less confrontational too, if that\u0026rsquo;s not quite your thing. In short, brilliance without collaboration is impossible. Helping is definitely mutual.\nThere are overlapping similarities behind executing on these tactics. In fact, it\u0026rsquo;s similar to how many started out in this industry. Work on interesting projects. That\u0026rsquo;s why you grew. There happened to be more knowledge to absorb at the time. Those tactics are parts of what made you become an expert in the first place. Many times people let their knowledge decay too far into ruin, instead of finding ways to build upon their knowledge.\nI happen to draw experience from many past projects. From using tools like Photoshop, Flash, and 3DS Max. Then writing games in C++, C#, and Python in game jams. Or implementing game algorithms on top of classic games. Haphazardly, learn some screencasting software to teach Django or present how to reverse engineer. Build a site that provides utility, then use that site\u0026rsquo;s data to visualize in d3. Then re-deploy the site in a half-dozen different ways to understand devops. And there\u0026rsquo;s also writing on this very blog1.\nThat\u0026rsquo;s a lot of projects. I\u0026rsquo;ve accidentally stumbled into many of them with an irresistible excitement. Others were like trudging through mud of demotivation. Interesting doesn\u0026rsquo;t necessarily mean you\u0026rsquo;ll love it, but it may expand your empathy for developers coming from a different perspective.\nThese projects will be frustrating. Some will be unfruitful; some of my projects were never finished. But it\u0026rsquo;s the fastest way I know how to learn. But the project has to be motivating enough to drive through the tough challenges. You need to trick yourself that the end goal is worth it, even though it\u0026rsquo;s only the journey that matters.\nIsn\u0026rsquo;t this advice the same as when you\u0026rsquo;re a beginner? Almost. You need to do more while working on these projects: think.\nYou must mentally refactor what you learn. That helps when you need to explain the concepts you\u0026rsquo;ve learned or how to build mental models of new, similar concepts. Try to derive mental schemas you can reapply in different contexts. Learn good object-oriented design patterns, then learn functional patterns. Try to describe OO patterns as functional ones and vice versa2. Try explaining coding style to a non-developer.\nWhy build schemas? They\u0026rsquo;re abstractions for the mind. They let you skip the implementation detail if needed. Engineers focus on the tools and the languages too often. Those things all have one thing in common: it\u0026rsquo;s knowledge that decays. Tools will always change; programming languages come and go. Building schemas is extracting your experience from the tools and languages you use. It\u0026rsquo;s high-density knowledge. To refine your schemas, you need to refactor your tool-specific knowledge. Instead of being an expert at one tool, could you generalize this skill to be better at a class of tools?\nAn example is working in a strongly-typed language. I tend to apply typed-language designs into other programs - even if it\u0026rsquo;s in a dynamically-typed language. Likewise in avoiding mutation and multi-threading - it improves understanding of the program.\nAfter using many languages, you become relatively ignorant of syntax. Instead, you\u0026rsquo;ll be scanning for larger patterns. Become the chess master that can recall layouts of chess positions through higher-level patterns instead of the beginner trying to memorize the location of every piece.\n","permalink":"http://localhost:1313/2015/11-mental-schemas.html","summary":"\u003cp\u003eIt is difficult to always be improving in the software industry. In creative\nfields, many artists \u003ca href=\"https://youtu.be/ikAb-NYkseI?t=9m41s\"\u003etalk\u003c/a\u003e about\n\u003ca href=\"http://www.goodreads.com/quotes/309485-nobody-tells-this-to-people-who-are-beginners-i-wish\"\u003echurn\u003c/a\u003e.\nWhen starting out, there\u0026rsquo;s an enormous amount of work to produce to get better.\nIf you\u0026rsquo;re new, there\u0026rsquo;s a massive amount of bad code you need to write. That\u0026rsquo;s\nOK, it\u0026rsquo;s necessary. But the rate of improvement decays as time progresses. As\nyour notoriety grows, you can no longer just crank out code to get better, how\ncan you preserve some rate of improvement? It feels like the rate of learning\nlooks like this:\u003c/p\u003e","title":"Mental Schemas"},{"content":" Software is always challenging to explain to non-engineers and having a metaphor is valuable to explain complex concepts. Bridges happen to be a good analogy to software. But the devil is always in the details.\nAny piece of software provides a benefit to its users. It\u0026rsquo;s similar to people using bridges to cross rivers. As with bridges, many kinds of software can solve the same problems.\nSome bridges support many cars and pedestrians which is analogous to a high-throughput like a server that can support many users. Others are very nice walkways with trees, a highly usable piece of software that supports only a few users. Most of the time, users only see the bridge from the top. Like seeing only the tip of an iceberg.\nIn the process of helping users accomplish a task, bridges need to overcome various forces and challenges. The ground may be very soft. The river may rise hundreds of feet. There might be severe rain or snow. There may be hurricane-force winds. Natural disasters may occur. Also, people that use the bridge to cross want to traverse by various means: walking, driving, biking, skating, etc..\nUnlike the real world, software is different in two ways: it\u0026rsquo;s cheap to construct and copy. That is, there are few upfront costs required to build. And replicating already constructed pieces is practically free. There\u0026rsquo;s a lot of implications from those two advantages - both good and bad.\nFirst, we can derive fast construction through modularization. We can build a component of a bridge and mass produce that component for reuse. Similar to Henry Ford\u0026rsquo;s modularization of car parts vastly speeding up car production. Since bridges can be constructed quickly and with little cost, it\u0026rsquo;s easy to correct an error in design after construction. Builders can get feedback, nearly immediately, from the environment it operates under. The feedback loop is fast - like building things out of Lego.\nBecause it\u0026rsquo;s so easy to build on the shoulders of the past giants, the industry quickly falls into becoming overmodularized and underdiciplined. It\u0026rsquo;s hard to build interconnected components when there are many competing, incompatible modules. And since it\u0026rsquo;s easy to course correcting along the way, the final result is usually inconsistent - beams of inconsistent lengths as the project progresses.\nAnd while building a bridge that lasts for a day is easy, building a bridge to stand for months or years is not easy. Seasoned builders have techniques and practices that can build these longer standing bridges at the cost of taking more time to build. Great builders try to anticipate all the environmental factors while supporting business requirements such as \u0026ldquo;it needs to have trees on top\u0026rdquo; or \u0026ldquo;have a toll booth on it to charge customers\u0026rdquo;. More than just the bridge, there are tools and instrumentations to verify that the bridge is operating normally at all times.\nSome bridges provide immense value to users and operators to the point where they are repaired and improved while actively being used. This requires foresight and infrastructure to support maintenance and improvements while the bridge is still operating.\nIn review, there\u0026rsquo;s a lot of challenges:\nOvercome terrain and weather. Potential environmental impact. Potentially support on-demand construction and maintenance while being operated. Instrumentation to identify problems. Tooling for operators to use. Maintain High adaptability because: it\u0026rsquo;s riders always want new features (lights, new vehicles, scenery/trees, etc.) it\u0026rsquo;s operators/owners want other changes more internal The last bullet is the one of the main reasons software is interesting to work on. How do you design a system that is highly adaptable with as few different components as possible? How does another engineer discover why there are a set of rivets in this particular I-beam? The technical decisions are endless.\nIf you like analogies to computers, you should check out Richard Feynman\u0026rsquo;s Lecture explaining computers.\nPhoto by Phillip Capper\n","permalink":"http://localhost:1313/2015/10-software-bridges.html","summary":"\u003chr\u003e\n\u003cp\u003eSoftware is always challenging to explain to non-engineers and having a metaphor\nis valuable to explain complex concepts. Bridges happen to be a good analogy to\nsoftware. But the devil is always in the details.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"10-software-bridges/MillauBridge.jpg\" alt=\"Millau Viaduct\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eAny piece of software provides a benefit to its users. It\u0026rsquo;s similar to people\nusing bridges to cross rivers. As with bridges, many kinds of software can solve\nthe same problems.\u003c/p\u003e\n\u003cp\u003eSome bridges support many cars and pedestrians which is analogous to a\nhigh-throughput like a server that can support many users. Others are very nice\nwalkways with trees, a highly usable piece of software that supports only a few\nusers. Most of the time, users only see the bridge from the top. Like seeing\nonly the tip of an iceberg.\u003c/p\u003e","title":"Software as Bridges"},{"content":"What is simple?\nRich Hickey makes a good abstract definition, but it can be difficult to translate to everyday code. I encourage you to watch that before returning to this. I\u0026rsquo;ll still be here.\nOk, let\u0026rsquo;s start at that definition. Hickey\u0026rsquo;s simplicity is the disentangling of concerns. It\u0026rsquo;s easy to convolute from what seems like straight-forward statement.\nFor example, a high-level example would be what domain-driven design proponents argue for. Separate solving your problem domain from the machinery that you use to solve it. Separate How from What or When.\nUsing inversion of control or dependency injection is simpler than creating new objects when it\u0026rsquo;s convenient. It\u0026rsquo;s separating object creation from objects that do work. This allows interchangeable collaborators and encourage reused.\nThis notion of simple can be more difficult. That sounds counter-intuitive at first. Simplicity may be more code. It may require more conceptual knowledge before modifying the code. But those are excuses for complexity. We could say we get less code by:\ncreating objects ad-hoc vs dependency injection. hard-coding instead of using abstractions. using arbitrary memory locations for code or shared lookups. For example, if and for are two separate concepts stemming from goto. But we don\u0026rsquo;t complain about how gotos lead to to more complex code. But if and for aren\u0026rsquo;t difficult concepts for us to grasp because we\u0026rsquo;re familiar with concepts from past experience.\nSimple designs also provide obvious extension points for expanding functionality. It can be jarring because the composition is the solution instead of a direct, hard-coded fashion. A personal example that has surfaced many times is input validation. It is sufficiently complex enough that just providing friendly names and a DSL may not suffice for domain rules.\nRich warns about confusing separation from compartmentalization. It\u0026rsquo;s easy to mix up moving code into smaller modules as separating concerns. Even inserting an interface between modules may not be simple enough. Instead, we must have code empathy to understand how much each module knows about one another:\nDoes a module have an implicit ordering of calls for a protocol? Do all collaborators need to know about this ordering? Does a collaborator expect specific side effects? Do collaborators share state? Does a object know about it\u0026rsquo;s collaborator\u0026rsquo;s collaborators? It\u0026rsquo;s a perfect example of compartmentalization are typical usages of Ruby\u0026rsquo;s include for modules. It is only a method of splitting a class\u0026rsquo; code across multiple files instead of splitting its responsibilities into separate objects.\nJavaScript Unsuprisingly, this simplicity is what makes Clojure (and other LISPs) compelling. LISPs are simpler than most other progamming languages.\nLet\u0026rsquo;s compare by trying describe the syntax of JavaScript (without pulling in compiler theory). If we\u0026rsquo;re explain what\u0026rsquo;s the meaning of every syntactic feature of JavaScript, it would be something like this:\nJS file contains many statements: statements separated by ; or blocks { } Expressions may be one of the following: ( expr ) for a parenthesized expression. 123 are numbers (floats). \u0026quot;string\u0026quot;, 'string' are strings. /reg-exp/ are regular expressions. null is the null type. true and false are boolean values. bar() is a function call. new Object() creates a new object. delete obj.field unassigns the value from the object\u0026rsquo;s field member. [expr1, expr2, ...] are array literals. {name1: expr1} are object literals. foo = expr is variable assignment. Variable may or may not exist. obj.method is the function of the object\u0026rsquo;s method, but does not bind obj to this. expr1 op expr2 is an two-arg operator expression for: ||, \u0026amp;\u0026amp;, \u0026lt;, \u0026lt;=, \u0026gt;, \u0026gt;=, ==, ===, |, \u0026amp;, ^, ~, +, -, *, /, \u0026lt;\u0026lt;, \u0026gt;\u0026gt;, \u0026lt;\u0026lt;\u0026lt;, \u0026gt;\u0026gt;\u0026gt; op expr is an unary operator for: -, ! function foo(bar, baz...) { statements } is a function definition. Definitions are implicitly above other statements within the same list of statements. function(bar, baz...) { statements } is an annoymous function foo.bar is accessing the bar property of object foo foo['bar'] is accessing the bar property of object foo. Does not bind this. foo.bar() is a method invocation of bar on object foo. expr ? expr : expr is an inlined if-else statement. this is the local execution context for a function. typeof variable for getting the data type of the variable. object instanceof class for checking object type. Assignment Operators: +=, -=, *=, /=, \u0026lt;\u0026lt;=, \u0026gt;\u0026gt;=, ~=, \u0026amp;=, ^=, |=, ++, --, \u0026lt;\u0026lt;\u0026lt;=, \u0026gt;\u0026gt;\u0026gt;= Statements may be one of the following: with(expr) { statements } uses expr as the local context for statements. if (cond) { statements } is an if statement Which may have an arbitrary number of else if clause. Which may end in an else clause. for (stmt; cond; stmt) { statements } is a for-loop for (variable in object) { statments } is a for-each-like loop try { statments } catch (variable) { statements } for exception catching throw err to throw exceptions. while (expr) { statements } is a while loop var foo, bar is a variable definition break breaks loop control flow continue breaks current iteration of loop control flow return expr returns an expression and exits current function Any expression This doesn\u0026rsquo;t fully cover the rules of having a program understand JavaScript at a syntactic level:\nOrder of operations for operators (eg - \u0026lt;= vs ||) Optional characters in the syntax (eg - if (cond) foo;) Error recovery (automatic semicolon insertion). This isn\u0026rsquo;t covering what\u0026rsquo;s inside a standard library of JavaScript (node, browers, etc). Libraries are not technically part of the language itself.\nAnd JavaScript is argubly one of the easier languages to write up these rules in comparison to Python, Java, or C.\nNow let\u0026rsquo;s look at how simple Clojure (a LISP) is in comparison:\nA clojure file consists of many expressions Expressions are data literals (expr1 expr2) Lists with any number of expressions [expr1 expr2] Vectors with any number of expressions {expr-key expr-value} Maps/Hashes with any number of expressions as key-value pairs #{expr1 expr2} Sets with any number of expressions 123 Numbers \u0026quot;foo\u0026quot; Strings #\u0026quot;foo\u0026quot; Regular Expressions \\c Characters foo Symbols (think variable names). Symbols are namespaced. Semantically (expr1 arg1 arg2) means to call a function named expr1 with 2 arguments a macro named expr1 with 2 arguments (macros are special functions that hook into the compiler) Symbols evaluate to values Clojure has special forms. They look like function invocations, but have special meaning in clojure (def sym init) defines a variable sym to value init. Can optionally store metadata. (if test then else) is an if statement. then and else are expressions that if returns. (do expr1 expr2...) is a way to evaluate multiple expressions, returning only the last one. (let [var value...] expr1 expr2...) defines local variables for the expressions. let returns the last expression. Allow destructuring. (quote form) escapes form. So you can create a list literal or symbol that isn\u0026rsquo;t evaluated. Alias is 'form (var sym) refers to Var which is like a pointer to a value that a symbol is associated with. (fn name [args...] exprs..) is a function definition. Args can be destructured. (loop [var value...] exprs...) is a let-like expression that allows looping with recur. (recur exprs...) jumps back to the nearest outer loop expression with expression as the new variable values. (throw expr) throws an exception (try expr (catch expr)... (finally expr)) try expression. catch and finally are optional (monitor-enter x) (monitor-exit x) low-level locking primitives. Used only for clojure core. (.method instance arg) java interop to do method invocation. (new ClassName) java interop to create new instance (set! field expr) java interop to set a field This is relatively comprehensive description of Clojure\u0026rsquo;s syntax. Most of the special forms are no different from normal function invocations. Features normally found in the language are delegated to the standard library similar to the function invocation format. An example is the or operator. or is the composition of let and if:\n;; Clojure ;; defmacro is part of stdlib, that is an alias defining a named function with ;; metadata indicating its a macro (defmacro or ([] nil) ; zero args is always false ([x] x) ; one arg is simply x ([x \u0026amp; next] ; more args are nested or calls `(let [or# ~x] (if or# or# (or ~@next))))) Clojure avoids complexity common in other languages:\nNo special order of operations. The prefix-notation dictates the order of execution. Clojure treats , as whitespace. Only whitespace after the first whitespace character are optional. Macros are just functions whose arguments are lazily evaluated. This provides meta programming capabilities if needed while reducing the size of the meta programming API. Both Clojure and JavaScript are trying to solve a problem of expressing programs. But one seems to do it with fewer internal components.\nIt\u0026rsquo;s worth noting that Clojure could be simplier. Rich has made tradeoffs to leverage the JVM. State management is explicit, but not simple. Even something as small as ordered argument parameters for functions is a tradeoff in concision over potential readability.\nBut Clojure isn\u0026rsquo;t easy. It\u0026rsquo;s a departure from the C-family of languages. Clojure has large (Jvava) stacktraces. It\u0026rsquo;s common to hear developers complain about the number of parentheses. But it\u0026rsquo;s analogous to multi-responsibility classes in OO. Large objects can be an entirely separate article. Easy is something we can overcome. Complexity we can only paint over.\nThe beginner\u0026rsquo;s mindset can reveal what we internalize as complexity. I was always fascinated why first-time developers had difficulty grasping object-oriented programming. Ben Orenstein observed the same troubles: new developers usually write in a functional style. Beginners can easily learn functional programming, followed by object oriented programming. Yet, learning object oriented programming first makes learning functional programming more difficult.\nThe question to ask is: how can one express the problem with fewer internal components?\nValue Objects This an example I\u0026rsquo;ve looked into, but there are definitely other patterns in software worth looking at.\nIn the Object Oriented Programming space, this is the basis of good design. And to make this clear ahead of time: values objects are an improvement. But the way object-oriented languages employ them could be better.\nWhy? Traditional value objects look a lot like this:\n// Swift // object-y value object class Person { var firstName: String, lastName: String init(firstName: String, lastName: String) { self.firstName = firstName self.lastName = lastName } } // better value object struct Person { let firstName: String, lastName: String init(firstName: String, lastName: String) { self.firstName = firstName self.lastName = lastName } } What did we just do by doing this instead of a dictionary?\nWe excluded other libraries from using our value object unless they explicitly depend on our library. We must manually serialize this value object - one for each new value object we create. We must reimplement the behavior of value object. Behaviors like comparison, pretty-printing, copying, etc. Essentially, we start building our API for our value objects from scratch. A classic computer science data structure avoids most of those problems.\nMany languages have problems for the built-in data structures: Ruby\u0026rsquo;s inconsistent missing key handling vs objects, or verbose syntax. While both aren\u0026rsquo;t perfect, one is more general than the other.\nIdeally, value objects should conform to a generalized access pattern. Lists, arrays and dictionaries conform to some common access patterns: Iterators, Sequences, Mapping Functions, Printability.\nWrapping Up It\u0026rsquo;s never-ending quest to reduce complexity. Hopefully, I\u0026rsquo;ve laid out some things worth pondering. Some other patterns that can get a similar critical eye:\nInterface / Protocol design: Fewer or more methods are better? When there are too few methods? OOP: How many objects should we have in a system? Should they be dynamically reallocating or a stable system? Concurrency: Can we use the same patterns in single-threaded systems and multi-threaded ones? Distributed Systems: Why don\u0026rsquo;t we use the same patterns for distributed systems and single-system designs? Persistence: Why do we seek ORMs over the repository pattern? The goal is to be clear and concise, but it\u0026rsquo;s easy to be either verbose or terse.\n","permalink":"http://localhost:1313/2015/09-seeking-simplicity.html","summary":"\u003cp\u003eWhat is simple?\u003c/p\u003e\n\u003cp\u003eRich Hickey makes a good abstract definition, but it can be difficult to\ntranslate to everyday code. I encourage you to\n\u003ca href=\"http://www.infoq.com/presentations/Simple-Made-Easy\"\u003ewatch that\u003c/a\u003e before\nreturning to this. I\u0026rsquo;ll still be here.\u003c/p\u003e\n\u003cp\u003eOk, let\u0026rsquo;s start at that definition. Hickey\u0026rsquo;s simplicity is the \u003cstrong\u003edisentangling\nof concerns\u003c/strong\u003e. It\u0026rsquo;s easy to convolute from what seems like straight-forward\nstatement.\u003c/p\u003e\n\u003cp\u003eFor example, a high-level example would be what domain-driven design proponents\nargue for. Separate solving your problem domain from the machinery that you use\nto solve it. Separate How from What or When.\u003c/p\u003e","title":"Seeking Simplicity"},{"content":"It\u0026rsquo;s a bittersweet end to a chapter. I\u0026rsquo;ve thoroughly enjoyed my time at Pivotal Labs. I met a lot of great friends. I paired and talked with geniuses and newcomers alike. And I\u0026rsquo;d recommend anyone with an opportunity to work at Labs to take it immediately.\nI look back with great memories, shared termoil, and personal growth. As an introvert, it was a boundary-expanded endevor: pair programming every day. I learned the value of tests which is evident to most of the major open source work I\u0026rsquo;ve contributed to. I\u0026rsquo;ve sharpened my mind by the discussions I\u0026rsquo;ve had there.\nPivotal provided accelerated growth that I couldn\u0026rsquo;t have receive from normal companies. Labs provides a unique way to learn on a wide range of skills in a few years:\nLearning professional software engineering for mobile and web development. How to run software teams. How to integrate design, engineers, and product together. What makes a good team? Testing in variety of contexts. Why test? Continuous delivery / integration. Software stacks. Sustainable software development. Teaching and explaining topics to both developers and non-developers. Also, I learned about the people that create software:\nHow people think and learn tools and languages. How processes can shape everyday behaviors. What can make people productive. Communicating well is a tough problem. I thank everyone who I have had the chance to worked with. I thank you pair for letting me type (I love it a bit too much) and experiencing how much I fail at pressing the right buttons too. Please, keep in touch.\nBut it\u0026rsquo;s time to experience startup life. I\u0026rsquo;ll be joining Mayvenn working on Clojure full-time. The clojure community has been a place I have been stealing ideas from since Clojure was first released into the world. It\u0026rsquo;s a special opportunity to use this language in anger. It\u0026rsquo;s impossible to have a perfect langauge, but it doesn\u0026rsquo;t hurt to expand to new forms of thought. That\u0026rsquo;s for another article.\nAs a polyglot, I\u0026rsquo;m impartial to tying any individual programming language. I\u0026rsquo;ve tinkered from assembly to Ruby. But it\u0026rsquo;s a great opportunity to learn from the community and tools that have inspired me a lot.\nI will continue to contribute and watch the Apple community grow. But I\u0026rsquo;m stepping up to learn as much as functional programming has to offer in practice. And I\u0026rsquo;ll likely spill it back over to this community.\nAnd I\u0026rsquo;ll definitely be writing more here, since I have less avenues to explain my thoughts on a more regular basis.\n","permalink":"http://localhost:1313/2015/08-moving-on.html","summary":"\u003cp\u003eIt\u0026rsquo;s a bittersweet end to a chapter. I\u0026rsquo;ve thoroughly enjoyed my time at Pivotal\nLabs. I met a lot of great friends. I paired and talked with geniuses and\nnewcomers alike. And I\u0026rsquo;d recommend anyone with an opportunity to work at Labs to\ntake it immediately.\u003c/p\u003e\n\u003cp\u003eI look back with great memories, shared termoil, and personal growth. As an\nintrovert, it was a boundary-expanded endevor: pair programming every day. I\nlearned the value of tests which is evident to most of the major open source\nwork I\u0026rsquo;ve contributed to. I\u0026rsquo;ve sharpened my mind by the discussions I\u0026rsquo;ve had\nthere.\u003c/p\u003e","title":"Moving On"},{"content":"It\u0026rsquo;s no secret that I\u0026rsquo;ve been interested in testing. Most of the work I\u0026rsquo;ve done are around example-based testing. While useful, it\u0026rsquo;s interesting to look at other communities for inspiration. I\u0026rsquo;m specifically fascinated in the functional programming community. Generative testing in particular. It was popularized in the early 2000s by a famous implementation in Haskell, QuickCheck.\nIn short, generative testing is allows you specify properties your software should have. Then the testing library generates test cases. It\u0026rsquo;s an alternative path the functional community has taken when it comes to testing. This becomes evident since testing functional code becomes mostly boilerplate management:\n;; Clojure Test (are [x y] (= x y) (add5 5) 10 (add5 2) 7 (add5 -5) 0) ;; Alternative (drier) representation (are [x y] (= (add5 x) y) 5 10 2 7 -5 0) This clojure example shows how functional communities try to remove the boilerplate common in traditional unit testing libraries. There are no test method names, assertions separated from the action. It\u0026rsquo;s not behavior driven development, but they share the goal of improving software quality. Notice how the test data is usually front and foremost in functional programming.\nGenerative tests are the next iteration. They are abstraction representations of tests like the one above:\n;; clojure.test.check (prop/for-all [x gen/int] (= (add5 x) (+ 5 x))) This reads:\nFor all integers x, add5 of x should equal x added by 5.\nIn fact, it reads a lot like a proof statement. And in a simplified form, the generative testing library tries to generate the smallest counter example.\nHowever, this isn\u0026rsquo;t a good property test. It completely duplicates the possible implementation. Instead, it might be better to write other properties that result from the implementation:\n(prop/for-all [x gen/int] (= (- (add5 x) x) 5)) This reads:\nFor all integers x, subtracting x from the add5 of x should always equal 5.\nIt (arguably) prevents us from rewriting the implementation. Instead, it tries to state some known truth of the code we\u0026rsquo;re testing. This style of thinking is definitely not natural to a example-based testers (for me at least). The 3 most common ways of writing property-based tests are:\nDescribe an inverse relationship using multiple functions. A good example of this is encoding and decoding. A property test of JSON encoding can be that decode(encode(value)) == value. Describe a relationship of the inputs to its outputs. The concatentation of two arrays preserves sizes: len(a) + len(b) == len(a + b). Use an existing implementation. Use an array to test a circular buffer implementation. Or use an existing base64 encoder to test your new faster version. Generative tests shine for exploratory testing where edge cases tend to surface bugs. But it\u0026rsquo;s not a complete replacement to a traditional test suite. An example-based test suite can reliably reproduce significant cases: a known happy-path or a previously discovered bug. Both suites compliment each other well.\nInstead of focusing on ease of writing and maintaining tests, generative testing focuses on discovering new bugs.\nAn implementation of QuickCheck is also particularly fasinating. It\u0026rsquo;s a great example of a well-designed functional program. If you\u0026rsquo;re interested in an implementation for Objective-C and Swift, check out Fox.\n","permalink":"http://localhost:1313/2015/07-Generative-Testing.html","summary":"\u003cp\u003eIt\u0026rsquo;s no secret that I\u0026rsquo;ve been interested in testing. Most of the \u003ca href=\"https://github.com/pivotal/cedar\" title=\"Cedar - BDD for Objective-C\"\u003ework\u003c/a\u003e\n\u003ca href=\"https://github.com/Quick/Quick\" title=\"Quick - BDD for Swift and Objective-C\"\u003eI\u0026rsquo;ve\u003c/a\u003e \u003ca href=\"https://github.com/Nimble/Nimble\" title=\"Nimble Matcher Library for Swift and Objective-C\"\u003edone\u003c/a\u003e are around example-based testing. While useful,\nit\u0026rsquo;s interesting to look at other communities for inspiration. I\u0026rsquo;m specifically\nfascinated in the functional programming community. Generative testing in\nparticular. It was popularized in the early 2000s by a famous implementation in\nHaskell, \u003ca href=\"https://hackage.haskell.org/package/QuickCheck\"\u003eQuickCheck\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIn short, generative testing is allows you specify properties your software\nshould have. Then the testing library \u003cem\u003egenerates\u003c/em\u003e test cases. It\u0026rsquo;s an\nalternative path the functional community has taken when it comes to testing.\nThis becomes evident since testing functional code becomes mostly boilerplate\nmanagement:\u003c/p\u003e","title":"Generative Testing"},{"content":"Note: This previously was on Pivotal Labs blog.\nIn the previous article, we used TDD to parse JSON into our Person model and refactored the code under test. In part 2, we\u0026rsquo;re going to refactor the code further to be more reusable and extendable. All the code in this article will also be in the same repository.\nRedesign The refactorings in the previous article were fairly straightforward and mechanical. Ultimately, we’ll need to break apart different concerns of this code. One approach would be to start with some questions:\nWhat is the problem we\u0026rsquo;re trying to solve? How can the problem be broken into smaller problems to solve in separate pieces? What is domain-knowledge code? What is generic, machinery code? How can we separate them? What are the tradeoffs of the solution? There are many possible solutions, but I\u0026rsquo;ll present just one which tries to maximize flexibility and minimize the machinery.\nWhen designing an API, it’s common to confuse easy with simple. I recommend watching Rich Hickey’s Simple Made Easy Talk. In summary, simplicity is about keeping things unentangled.\nHere\u0026rsquo;s how the solution tries to answer the questions:\nWhat is the problem we\u0026rsquo;re trying to solve? Data Mapping. Converting one tree of value objects into another tree of value objects. This code should treat the input of values as untrusted data and avoid any exceptions. This is functional - it\u0026rsquo;s not covering anything related to network code.\nHow can the problem be broken into smaller problems to solve in separate pieces? Data mapping is a fractal problem. For example, converting string to integer is a subset of converting an array of strings to an array of integers.\nWhat is domain-knowledge code? What is generic, machinery code? How can we separate them? The domain knowledge are the specific values that are input and output. Names of things: fields, objects, and properties are all domain specific. The operations that transform the input into the output are generic, machinery code. They can be transposed to different problem domains (for instance, JSON vs. XML).\nWhat are the tradeoffs of the solution? Composition increases the number of lines of code. If publicly exposed, this greatly increases the surface area of the API to test and for end-users to learn.\nBuilding the Abstraction So we want a simpler abstraction. Making the code more uniform is what an abstraction is for. So let’s go with something similar to the original method.\n@protocol Mapper - (id)objectFromJSONObject:(id)jsonObject error:(__autoreleasing NSError **)error; @end Refraining from adding more methods is generally a good thing. Otherwise the interface becomes like the Java Set interface with 15 methods. Each method added to an interface leaks the abstraction - dictating implementation details. It’s better to use composition to make an abstraction easier to use instead of mixing the ease and abstraction together. For example, the one Mapper method implicitly dictates a synchronous API.\nWe’ll keep the public interface the same until the end for now.\nSo lets move the code previously in methods into separate classes. We’ll \u0026ldquo;talk\u0026rdquo; to other methods through the Mapper protocol. For example, -[peopleFromJSONObject:error:] is extracted into two parts:\nA mapper that uses another mapper on every element of an array. (Pure machinery) A mapper to convert JSON into a Person object. (More domain) Here’s the mapper for every element in an array:\n@interface ArrayMapper \u0026lt;Mapper\u0026gt; @property (nonatomic) id\u0026lt;Mapper\u0026gt; mapper; - (instance)initWithItemMapper:(id\u0026lt;Mapper\u0026gt;)mapper; @end @implementation ArrayMapper // … init method here … - (id)objectFromSourceObject:(id)jsonObject error:(__autoreleasing NSError **)error { NSMutableArray *transformedItems = [NSMutableArray array]; for (id item in jsonObject) { NSError *itemError = nil; id transformedItem = [self.itemMapper objectFromSourceObject:item error:\u0026amp;itemError]; if (itemError) { *error = itemError; return nil; } else { [transformedItems addObject:transformedItem]; } } return transformedItems; } @end We can further break apart the theoretical Person Mapper class. There is the domain of the keys and models to map, but the actual process is purely machinery work. We’ll generically map keys of one object to keys of another object using KVC to remove a custom class.\n@interface ObjectMapper : NSObject \u0026lt;Mapper\u0026gt; @property (nonatomic) Class classOfObjectToCreate; @property (nonatomic, copy) NSDictionary *jsonKeysToFields; @property (nonatomic, copy) NSDictionary *fieldsToMappers; - (instancetype)initWithGeneratorOfClass:(Class)classOfObjectToCreate jsonKeysToFields:(NSDictionary *)jsonKeysToFields fieldsToMappers:(NSDictionary *)fieldsToMappers; @end @implementation ObjectMapper // … init method here … - (id)objectFromJSONObject:(id)jsonObject error:(__autoreleasing NSError **)error { *error = nil; id object = [[self.classOfObjectToCreate alloc] init]; for (id jsonKey in self.jsonKeysToFields) { id field = self.jsonKeysToFields[jsonKey]; // note: this is an assumption here. We may not want to always use key path. id value = [jsonObject valueForKeyPath:jsonKey]; id\u0026lt;Mapper\u0026gt; valueMapper = self.fieldsToMappers[field]; if (valueMapper) { value = [valueMapper objectFromJSONObject:value error:error]; if (*error) { return nil; } } if (value) { // setValue:forKey: fails if value is nil [object setValue:value forKey:field]; } } return object; } @end You can see the other refactors in the tagged repository. But the basic goal is move all methods into separate classes that conform to our new Mapper protocol. But the methods tend to bind details of the machinery of data mapping and the domain of what objects we’re specifically operating on.\nNow our high-level solution becomes an object composition problem:\n- (Person *)personFromJSONObject:(id)json error:(__autoreleasing NSError **)error { id\u0026lt;Mapper\u0026gt; stringToNumberMapper = [[StringToNumberMapper alloc] init]; id\u0026lt;Mapper\u0026gt; friendMapper = [[ObjectMapper alloc] initWithGeneratorOfClass:[Person class] jsonKeysToFields:@{@\u0026#34;id\u0026#34;: @\u0026#34;identifier\u0026#34;, @\u0026#34;name\u0026#34;: @\u0026#34;name\u0026#34;, @\u0026#34;height\u0026#34;: @\u0026#34;height\u0026#34;} fieldsToMappers:@{@\u0026#34;height\u0026#34;: stringToNumberMapper}]; id\u0026lt;Mapper\u0026gt; friendsMapper = [[ArrayMapper alloc] initWithItemMapper:friendMapper]; NSDictionary *jsonKeysToFields = @{@\u0026#34;id\u0026#34;: @\u0026#34;identifier\u0026#34;, @\u0026#34;name\u0026#34;: @\u0026#34;name\u0026#34;, @\u0026#34;height\u0026#34;: @\u0026#34;height\u0026#34;, @\u0026#34;friends\u0026#34;: @\u0026#34;friends\u0026#34;}; NSDictionary *fieldsToMappers = @{@\u0026#34;height\u0026#34;: stringToNumberMapper, @\u0026#34;friends\u0026#34;: friendsMapper}; id\u0026lt;Mapper\u0026gt; objectMapper = [[ObjectMapper alloc] initWithGeneratorOfClass:[Person class] jsonKeysToFields:jsonKeysToFields fieldsToMappers:fieldsToMappers]; return [objectMapper objectFromJSONObject:json error:error]; } This is more code! But functional programmers might recognize this as a restricted, verbose version of partial functions. They maximize the amount of flexibility and code reuse - especially if they’re pure functions. Data mapping happens to fit a purely functional operation: converting one value object to another. Unfortunately, Objective-C doesn’t treat functions as first class citizens in the language (and therefore, it isn\u0026rsquo;t idiomatic to compose functions). Object-oriented programming can still represent partial functions, but with more boilerplate. In exchange for a bit more code our objects become more SOLID, honoring the concepts of Single Responsibility and Dependency Inversion.\nTaking it to the Extreme To indicate that this protocol works for more than just JSON objects, we can rename the method on Mapper:\n@protocol Mapper \u0026lt;NSObject\u0026gt; - (id)objectFromSourceObject:(id)sourceObject error:(__autoreleasing NSError **)error; @end But it’s pretty much the same otherwise. Using Mapper, we can expand to cover all behavioral aspects of data mapping and try to clean up the remaining private methods we extracted earlier. Abstracting common operations to be more declarative can make the associated code more useful for the general data mapping problem we’re solving. Let’s look at a new ChainMapper class:\n@interface ChainMapper : NSObject \u0026lt;Mapper\u0026gt; @property (nonatomic, copy) NSArray *mappers; - (instancetype)initWithMappers:(NSArray *)mappers; @end @implementation ChainMapper // … init method here … - (id)objectFromSourceObject:(id)sourceObject error:(__autoreleasing NSError **)error { *error = nil; id result = sourceObject; for (id\u0026lt;Mapper\u0026gt; mapper in self.mappers) { result = [mapper objectFromSourceObject:result error:error]; if (*error) { return nil; } } return result; } @end This class simply chains each mapper’s results to the one after it, unless an error occurs. So the only public method on PersonParser changes to utilize more of this protocol:\n- (Person *)personFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error { JSONDataToObjectMapper *jsonMapper = [[JSONDataToObjectMapper alloc] initWithErrorDomain:kParserErrorDomain errorCode:kParserErrorCodeBadData]; ErrorIfMapper *errorMapper = [[ErrorIfMapper alloc] initWithErrorDomain:kParserErrorDomain errorCode:kParserErrorCodeNotFound userInfo:@{NSLocalizedDescriptionKey: @\u0026#34;No person was found\u0026#34;} errorIfJSONKeyExists:@\u0026#34;message\u0026#34;]; NSArray *mappersToTry = @[jsonMapper, errorMapper, [self personMapper]]; ChainMapper *mapper = [[ChainMapper alloc] initWithMappers:mappersToTry]; return [mapper objectFromSourceObject:jsonData error:error]; } Which essentially describes a data flow diagram:\njsonMapper -\u0026gt; errorMapper -\u0026gt; personMapper -\u0026gt; Person Object | | | error error error Oh yeah, did I forget to mention all the tests still pass? We didn’t change the public API, so we didn’t change any tests. You can view all the code we changed up to this point.\nRunning With Random Seed: 23518\n\u0026hellip;\u0026hellip;\u0026hellip;.\nFinished in 0.1246 seconds\n10 examples, 0 failures\nExtending the Design Now let’s expand the design to something it wasn’t managing before. Optional mapping.\nAn optional mapping is a mapping that can succeed by not mapping a value. An example usage is when mapping arrays.\nInput: @[@\u0026#34;foo\u0026#34;, @\u0026#34;10\u0026#34;, @\u0026#34;20\u0026#34;] \u0026lt;mapping magic\u0026gt; Output: @[@10, @20] The first element in the input is dropped from the array as invalid input (it can’t be converted to a number). But we still want the possibility that we can reject the entire array if we want.\nSo we need to modify the contract of our protocol. I’ll propose adding a key to the userInfo of NSErrors returned:\nextern NSString *kIsNonFatalKey; @protocol Mapper \u0026lt;NSObject\u0026gt; - (id)objectFromSourceObject:(id)jsonObject error:(__autoreleasing NSError **)error; @end If this key is set to @YES, then mappers can choose to suppress the error and continue. A perfect use is for the ArrayMapper to simply drop that value when producing the array. The new OptionalMapper simply converts an error from a mapper its given into this non-fatal error. Composing both gives us our bigger solution:\nNSDictionary *jsonKeysToFields = @{@\u0026#34;id\u0026#34;: @\u0026#34;identifier\u0026#34;, @\u0026#34;name\u0026#34;: @\u0026#34;name\u0026#34;, @\u0026#34;height\u0026#34;: @\u0026#34;height\u0026#34;}; NSDictionary *fieldsToMappers = @{@\u0026#34;height\u0026#34;: stringToNumber, @\u0026#34;id\u0026#34;: required, @\u0026#34;name\u0026#34;: required}; id\u0026lt;Mapper\u0026gt; friendMapper = [[ObjectMapper alloc] initWithGeneratorOfClass:[Person class] jsonKeysToFields:jsonKeysToFields fieldsToMappers:fieldsToMappers]; id\u0026lt;Mapper\u0026gt; objectToFriendOrEmpty = [[OptionalMapper alloc] initWithMapper:friendMapper]; id\u0026lt;Mapper\u0026gt; objectToFriends = [[ArrayMapper alloc] initWithItemMapper:objectToFriendOrEmpty]; The code changes are relatively straightforward. You can see the final code in the repository.\nClosing Thoughts All the composition gives us significant flexibility to extend the system. An example is a generic object-to-object mapper - we can build a mapper that:\nUses reflection to figure out mapping of JSON keys to model properties Automatically determine which types to parse Add fallback parsing strategies (e.g. - parsing all the known RFC formats of date strings) Type-checking input Allowing end-user customization when required. All of which builds on top of existing functionality. A perfect example is Hydrant’s ReflectiveMapper class (which is verbose simply because it is an immutable builder too). Most of it’s functionality is achieved by composing other objects in Hydrant.\nTry it at Home Obviously, the example code for this article isn’t thorough in covering all the error cases and is for demonstrative purposes. There are many ways to expand this code:\nCover more edge cases Check NSError ** isn’t NULL before using it Check for types of the source object before processing them Handle parsing other data types (XML, YAML, etc.) If we’re making the individual mapper classes public, we should consider adding tests to them. As well as areas that haven’t seen a design treatment:\nHow can we support key paths and key values simultaneously? Is using a userInfo key a good approach for this? Can we generalize ArrayMapper to more than arrays? How can we generalize ObjectMapper to be recursive? How can we support mapping many-to-many relationships? (e.g. - day, time keys into a date property). How can we serialize something back into JSON without having to repeat ourselves (the end-user)? How can we provide enough information for end-users to debug when a mistake in data mapping has been made? Many of these concepts are explored in the Hydrant project, but I encourage you to explore the problem and possible solutions on your own.\n","permalink":"http://localhost:1313/2014/06-Parsing-JSON-in-Objective-C-Part-2.html","summary":"\u003cp\u003e\u003cem\u003eNote: This previously was on\n\u003ca href=\"http://pivotallabs.com/parsing-json-objective-c-part-2/\"\u003ePivotal Labs blog\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn the \u003ca href=\"05-parsing-json-in-objective-c-part-1\"\u003eprevious article\u003c/a\u003e, we used TDD to\nparse JSON into our \u003ccode\u003ePerson\u003c/code\u003e model and refactored the code under test. In part\n2, we\u0026rsquo;re going to refactor the code further to be more reusable and extendable.\nAll the code in this article will also be in the\n\u003ca href=\"https://github.com/jeffh/ParsingJSON/\"\u003esame repository\u003c/a\u003e.\u003c/p\u003e\n\u003ch1 id=\"redesign\"\u003eRedesign\u003c/h1\u003e\n\u003cp\u003eThe refactorings in the previous article were fairly straightforward and\nmechanical. Ultimately, we’ll need to break apart different concerns of this\ncode. One approach would be to start with some questions:\u003c/p\u003e","title":"Parsing JSON in Objective-C - Part 2"},{"content":"This post was original written on the Pivotal Labs Blog.\nJSON parsing is a frequent task for clients interfacing with any recent web API. Those web services frequently vary in quality:\nIs the API following a RESTful design pattern? Is it providing an object graph or just a single/collection of objects in the JSON response? What are the data types of the fields being returned? Can they be relied upon? How much work are clients duplicating to work around the server (e.g. - Performance, Business Logic, etc.)? If you have full control of the resulting API endpoints, then it is easy to build or fix the API to your client’s specific needs. Controlling the incidental complexity can be challenging for APIs you do not control, or which have to support a variety of clients.\nI’ll talk about the process of developing a JSON parser in Objective-C using TDD. Then we’ll simplify and abstract it as if we were to build a library. While this code isn’t applicable for everyone, the process is the meaty part of it to take away.\nPotential Problems Let’s look at an example of a not-so-great API around managing a user’s contacts. I’m just going to specify enough details to show the pain points, although plenty of APIs do have similar problems. Some properties of potentially problematic APIs:\nAn object graph is returned per API request. Each endpoint returns a different view of the object in question. JSON keys may or may not be there. If they are, they may be null. Inconsistent / Unsanitized Data: Sometimes the data included is invalid or incorrect and must be filtered out. Error responses are inconsistent in HTTP status and body format. Parsing a Simple Object Graph For the rest of the article, I’m going to talk about techniques to convert this JSON (roughly):\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jeff Hui\u0026#34;, \u0026#34;height\u0026#34;: 70, \u0026#34;friends\u0026#34;: [ {}, { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Andrew Kitchen\u0026#34; } ] } into the model(s):\n@interface Person : NSObject @property (nonatomic) id identifier; @property (nonatomic) NSString *name; @property (nonatomic) NSUInteger height; @property (nonatomic) NSArray *friends; @end All the code, and its evolution, is available on this tagged repository. I’ll be mentioning tags along the way.\nThe Naive Solution In the name of YAGNI, we start by blissfully parsing the JSON. Eventually, we’ll add error cases.\nIt’s easy to test drive this. I’ll be using Cedar.\ndescribe(@\u0026#34;PersonParser\u0026#34;, ^{ __block PersonParser *subject; beforeEach(^{ subject = [[PersonParser alloc] init]; }); describe(@\u0026#34;converting JSON response to a person object\u0026#34;, ^{ __block Person *person; __block NSData *data; // subjectAction runs after all beforeEaches for each it block subjectAction(^{ person = [subject personFromJSONData:data]; }); context(@\u0026#34;successfully parsing a person\u0026#34;, ^{ beforeEach(^{ data = [Fixture jsonDataFromObject:@{ @\u0026#34;id\u0026#34;: @1, @\u0026#34;name\u0026#34;: @\u0026#34;Jeff Hui\u0026#34;, @\u0026#34;height\u0026#34;: @70, @\u0026#34;friends\u0026#34;: @[ @{ @\u0026#34;id\u0026#34;: @2, @\u0026#34;name\u0026#34;: @\u0026#34;Andrew Kitchen\u0026#34; } ] }]; }); it(@\u0026#34;should return a person\u0026#34;, ^{ person.identifier should equal(@1); person.firstName should equal(@\u0026#34;Jeff\u0026#34;); person.lastName should equal(@\u0026#34;Hui\u0026#34;); person.height should equal(70); person.friends.count sholld equal(1); Person *aFriend = person.firstObject; aFriend.identifier should equal(@2); aFriend.firstName should equal(@\u0026#34;Andrew\u0026#34;); aFriend.lastName should equal(@\u0026#34;Kitchen\u0026#34;); }); }); }); }); With failing tests, we need some implementation:\n- (Person *)personFromJSONData:(NSData *)jsonData { id json = [NSJSONSerialization jsonObjectFromData:jsonData options:0 error:nil]; Person *person = [[Person alloc] init]; person.identifier = json[@\u0026#34;id\u0026#34;]; NSArray *nameComponents = [json[@\u0026#34;name\u0026#34;] componentsSeparatedByString:@\u0026#34; \u0026#34;]; person.firstName = nameComponents.firstObject; person.lastName = nameComponents.lastObject; NSMutableArray *friends = [NSMutableArray array]; for (NSDictionary *friendDict in json[@\u0026#34;friends\u0026#34;]) { [friends addObject:[self personFromJSON:friendDict]]; } person.friends = friends; return person; } Review all the code at first tag. All done, ship it! But what about the error cases?\nError Handling You\u0026rsquo;re probably cringing right now because there\u0026rsquo;s no error handling yet:\nWhat happens if the JSON doesn\u0026rsquo;t parsed successfully? What if JSON keys don\u0026rsquo;t exist? Are the types of the JSON objects that we expect? We need a way to tell the rest of our program when we failed to parse something. I’ll use the standard Objective-C pattern of accepting an error pointer.\n// ... describe(@\u0026#34;converting JSON response to a Person object\u0026#34;, ^{ __block Person *person; __block NSData *data; __block NSError *error; // subjectAction runs after all beforeEaches for each it block subjectAction(^{ person = [subject personFromJSONData:data error:\u0026amp;error]; }); context(@\u0026#34;with a valid JSON object of a person\u0026#34;, ^{ beforeEach(^{ id json = @{@\u0026#34;id\u0026#34;: @1, @\u0026#34;name\u0026#34;: @\u0026#34;Jeff Hui\u0026#34;, @\u0026#34;height\u0026#34;: @70, @\u0026#34;friends\u0026#34;: @[@{@\u0026#34;id\u0026#34;: @2, @\u0026#34;name\u0026#34;: @\u0026#34;Andrew Kitchen\u0026#34;, @\u0026#34;height\u0026#34;: @86}]}; data = [Fixture jsonDataFromObject:json]; }); it(@\u0026#34;should return a person\u0026#34;, ^{ person.identifier should equal(@1); person.name should equal(@\u0026#34;Jeff Hui\u0026#34;); person.height should equal(70); person.friends.count should equal(1); Person *aFriend = person.friends.firstObject; aFriend.identifier should equal(@2); aFriend.name should equal(@\u0026#34;Andrew Kitchen\u0026#34;); aFriend.height should equal(86); }); it(@\u0026#34;should return no error\u0026#34;, ^{ error should be_nil; }); }); context(@\u0026#34;with a valid JSON object of an error\u0026#34;, ^{ beforeEach(^{ id json = @{@\u0026#34;message\u0026#34;: @\u0026#34;Person not found\u0026#34;}; data = [Fixture jsonDataFromObject:json]; }); it(@\u0026#34;should return nil\u0026#34;, ^{ person should be_nil; }); it(@\u0026#34;should return an error indicating no person was given\u0026#34;, ^{ error.domain should equal(kParserErrorDomain); error.code should equal(kParserErrorCodeNotFound); error.userInfo should equal(@{NSLocalizedDescriptionKey: @\u0026#34;No person was found\u0026#34;}); }); }); }); // ... This doesn’t compile since we changed the API contract. So let\u0026rsquo;s hack on the current implementation for the compiler:\n- (Person *)personFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error { The tests now compile and run, but fail. So now we can implement to check if the JSON data has an error message.\n- (Person *)personFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error { *error = nil; id json = [NSJSONSerialization JSONObjectWithData:jsonData options:0 error:nil]; if (json[@\u0026#34;message\u0026#34;]) { *error = [NSError errorWithDomain:kParserErrorDomain code:kParserErrorCodeNotFound userInfo:@{NSLocalizedDescriptionKey: @\u0026#34;No person was found\u0026#34;}]; return nil; } Person *person = [[Person alloc] init]; person.identifier = json[@\u0026#34;id\u0026#34;]; person.name = json[@\u0026#34;name\u0026#34;]; person.height = [json[@\u0026#34;height\u0026#34;] unsignedIntegerValue]; NSMutableArray *friends = [NSMutableArray array]; for (NSDictionary *friendDict in json[@\u0026#34;friends\u0026#34;]) { Person *aFriend = [[Person alloc] init]; aFriend.identifier = friendDict[@\u0026#34;id\u0026#34;]; aFriend.name = friendDict[@\u0026#34;name\u0026#34;]; aFriend.height = [friendDict[@\u0026#34;height\u0026#34;] integerValue]; [friends addObject:aFriend]; } person.friends = friends; return person; } This handles one case if the JSON object is an error message instead. This is getting larger, but let’s continue to cover more error cases. For brevity, we’ll only cover these error cases:\nChecking for [NSNull null] on the \u0026ldquo;height\u0026rdquo; key Checking for valid JSON Writing the tests is easy:\ndescribe(@\u0026#34;converting JSON response to a Person object\u0026#34;, ^{ // ... subjectAction(^{ person = [subject personFromJSONData:data error:\u0026amp;error]; }); // ... context(@\u0026#34;when a valid JSON object that has heights as nulls\u0026#34;, ^{ beforeEach(^{ id json = @{@\u0026#34;id\u0026#34;: @1, @\u0026#34;name\u0026#34;: @\u0026#34;Jeff Hui\u0026#34;, @\u0026#34;height\u0026#34;: [NSNull null], @\u0026#34;friends\u0026#34;: @[@{@\u0026#34;id\u0026#34;: @2, @\u0026#34;name\u0026#34;: @\u0026#34;Andrew Kitchen\u0026#34;, @\u0026#34;height\u0026#34;: [NSNull null]}]}; data = [Fixture jsonDataFromObject:json]; }); it(@\u0026#34;should return a person\u0026#34;, ^{ person.identifier should equal(@1); person.name should equal(@\u0026#34;Jeff Hui\u0026#34;); person.height should equal(0); person.friends.count should equal(1); Person *aFriend = person.friends.firstObject; aFriend.identifier should equal(@2); aFriend.name should equal(@\u0026#34;Andrew Kitchen\u0026#34;); aFriend.height should equal(0); }); it(@\u0026#34;should return no error\u0026#34;, ^{ error should be_nil; }); }); context(@\u0026#34;with a valid JSON object that has heights as strings\u0026#34;, ^{ beforeEach(^{ id json = @{@\u0026#34;id\u0026#34;: @1, @\u0026#34;name\u0026#34;: @\u0026#34;Jeff Hui\u0026#34;, @\u0026#34;height\u0026#34;: @\u0026#34;70\u0026#34;, @\u0026#34;friends\u0026#34;: @[@{@\u0026#34;id\u0026#34;: @2, @\u0026#34;name\u0026#34;: @\u0026#34;Andrew Kitchen\u0026#34;, @\u0026#34;height\u0026#34;: @\u0026#34;86\u0026#34;}]}; data = [Fixture jsonDataFromObject:json]; }); it(@\u0026#34;should return a person\u0026#34;, ^{ person.identifier should equal(@1); person.name should equal(@\u0026#34;Jeff Hui\u0026#34;); person.height should equal(70); person.friends.count should equal(1); Person *aFriend = person.friends.firstObject; aFriend.identifier should equal(@2); aFriend.name should equal(@\u0026#34;Andrew Kitchen\u0026#34;); aFriend.height should equal(86); }); it(@\u0026#34;should return no error\u0026#34;, ^{ error should be_nil; }); }); context(@\u0026#34;with an invalid JSON object\u0026#34;, ^{ __block NSError *jsonParseError; beforeEach(^{ data = [@\u0026#34;invalid\u0026#34; dataUsingEncoding:NSUTF8StringEncoding]; jsonParseError = nil; [NSJSONSerialization JSONObjectWithData:data options:0 error:\u0026amp;jsonParseError]; jsonParseError should_not be_nil; // make sure we got the error. }); it(@\u0026#34;should return nil\u0026#34;, ^{ person should be_nil; }); it(@\u0026#34;should return an error indicating the JSON failed to parse\u0026#34;, ^{ error.domain should equal(kParserErrorDomain); error.code should equal(kParserErrorCodeBadData); error.userInfo should equal(@{NSUnderlyingErrorKey: jsonParseError}); }); }); }); (from PersonParserSpec.mm)\nWith failing tests, let\u0026rsquo;s add to the implementation:\n- (Person *)personFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error { *error = nil; NSError *jsonError = nil; id json = [NSJSONSerialization JSONObjectWithData:jsonData options:0 error:\u0026amp;jsonError]; if (jsonError) { *error = [NSError errorWithDomain:kParserErrorDomain code:kParserErrorCodeBadData userInfo:@{NSUnderlyingErrorKey: jsonError}]; return nil; } if (json[@\u0026#34;message\u0026#34;]) { *error = [NSError errorWithDomain:kParserErrorDomain code:kParserErrorCodeNotFound userInfo:@{NSLocalizedDescriptionKey: @\u0026#34;No person was found\u0026#34;}]; return nil; } Person *person = [[Person alloc] init]; person.identifier = json[@\u0026#34;id\u0026#34;]; person.name = json[@\u0026#34;name\u0026#34;]; NSNumberFormatter *formatter = [[NSNumberFormatter alloc] init]; NSString *heightObject; if ([json[@\u0026#34;height\u0026#34;] isEqual:[NSNull null]]) { heightObject = @\u0026#34;\u0026#34;; } else { heightObject = [json[@\u0026#34;height\u0026#34;] description]; } person.height = [[formatter numberFromString:heightObject] unsignedIntegerValue]; NSMutableArray *friends = [NSMutableArray array]; for (NSDictionary *friendDict in json[@\u0026#34;friends\u0026#34;]) { Person *aFriend = [[Person alloc] init]; aFriend.identifier = friendDict[@\u0026#34;id\u0026#34;]; aFriend.name = friendDict[@\u0026#34;name\u0026#34;]; if ([json[@\u0026#34;height\u0026#34;] isEqual:[NSNull null]]) { heightObject = @\u0026#34;\u0026#34;; } else { heightObject = [friendDict[@\u0026#34;height\u0026#34;] description]; } aFriend.height = [[formatter numberFromString:heightObject] unsignedIntegerValue]; [friends addObject:aFriend]; } person.friends = friends; return person; } (from PersonParserSpec.mm)\nAnd we get our wonderful dots indicating all our tests pass:\nRunning With Random Seed: 16714 .......... Finished in 0.1280 seconds The full code is the tagged here. So we finished our Red and Green. Now its time to…\nRefactor We’re going to spend time refactoring without adding new features, such as additional parsing or error checking. Let\u0026rsquo;s keep in mind that refactoring is a gradient and not necessarily a binary operation. The intended reusability should dictate the amount of refactoring we do. Regularly running the tests ensures we don’t accidentally cause regressions while we refactor.\nOur ideal goal is to build a library that can perform as much of this work as possible. Of course, having all our code in one method isn’t reusable at all!\nThe obvious way to refactor is to break the code up into smaller methods.\nLet’s break it out:\n- (id)jsonObjectFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error converts incoming NSData to a JSON object. This wraps NSJSONSerialization work and providing a custom NSError. - (NSError *)errorMessageFromJSON:(id)json returns an error if an error JSON object is provided instead of the person object. - (Person *)personFromJSONObject:(id)json error:(__autoreleasing NSError **)error is where the magic goes. It produces Person objects from dictionaries. It doesn’t check for errors the previous(es) method does. - (NSArray *)friendsWithJSON:(id)jsonObject converts an array of dictionaries into an array of Person objects (for the friends key). The refactor is relatively straightforward. You can see the full refactor below:\n#pragma mark - Public - (Person *)personFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error { *error = nil; id json = [self jsonObjectFromJSONData:jsonData error:error]; if (*error) { return nil; } *error = [self errorMessageFromJSON:json]; if (*error) { return nil; } return [self personFromJSONObject:json error:error]; } #pragma mark - Private - (Person *)personFromJSONObject:(id)json error:(__autoreleasing NSError **)error { Person *person = [[Person alloc] init]; person.identifier = json[@\u0026#34;id\u0026#34;]; person.name = json[@\u0026#34;name\u0026#34;]; NSNumberFormatter *formatter = [[NSNumberFormatter alloc] init]; NSString *heightObject; if ([json[@\u0026#34;height\u0026#34;] isEqual:[NSNull null]]) { heightObject = @\u0026#34;\u0026#34;; } else { heightObject = [json[@\u0026#34;height\u0026#34;] description]; } person.height = [[formatter numberFromString:heightObject] unsignedIntegerValue]; person.friends = [self friendsWithJSON:json]; return person; } - (id)jsonObjectFromJSONData:(NSData *)jsonData error:(__autoreleasing NSError **)error { NSError *jsonError = nil; id json = [NSJSONSerialization JSONObjectWithData:jsonData options:0 error:\u0026amp;jsonError]; if (jsonError) { *error = [NSError errorWithDomain:kParserErrorDomain code:kParserErrorCodeBadData userInfo:@{NSUnderlyingErrorKey: jsonError}]; return nil; } return json; } - (NSError *)errorMessageFromJSON:(id)json { if (json[@\u0026#34;message\u0026#34;]) { return [NSError errorWithDomain:kParserErrorDomain code:kParserErrorCodeNotFound userInfo:@{NSLocalizedDescriptionKey: @\u0026#34;No person was found\u0026#34;}]; } return nil; } - (NSArray *)friendsWithJSON:(id)jsonObject { NSMutableArray *friends = [NSMutableArray array]; for (NSDictionary *friendDict in jsonObject[@\u0026#34;friends\u0026#34;]) { [friends addObject:[self personFromJSONObject:friendDict error:nil]]; } return friends; } The original method is much shorter now! And if we wanted to use some other portion of the parser, like the peopleFromJSONObject:error: method, we can do so without having to rewrite our code.\nAnd if we run our tests, they still pass.\nRunning With Random Seed: 48417 .......... Finished in 0.1168 seconds 10 examples, 0 failures In the Next Episode \u0026hellip; If this was in an application, this could be enough. In the next article, we\u0026rsquo;ll talk about how to redesign the code to increase its code reuse.\n","permalink":"http://localhost:1313/2014/05-Parsing-JSON-in-Objective-C-Part-1.html","summary":"\u003cp\u003e\u003cem\u003eThis post was original written on the\n\u003ca href=\"http://pivotallabs.com/parsing-json-in-objective-c\"\u003ePivotal Labs Blog\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eJSON parsing is a frequent task for clients interfacing with any recent web API.\nThose web services frequently vary in quality:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIs the API following a RESTful design pattern?\u003c/li\u003e\n\u003cli\u003eIs it providing an object graph or just a single/collection of objects in the\nJSON response?\u003c/li\u003e\n\u003cli\u003eWhat are the data types of the fields being returned? Can they be relied upon?\u003c/li\u003e\n\u003cli\u003eHow much work are clients duplicating to work around the server (e.g. -\nPerformance, Business Logic, etc.)?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you have full control of the resulting API endpoints, then it is easy to\nbuild or fix the API to your client’s specific needs. Controlling the incidental\ncomplexity can be challenging for APIs you do not control, or which have to\nsupport a variety of clients.\u003c/p\u003e","title":"Parsing JSON in Objective-C - Part 1"},{"content":"Languages that have dynamic introspection provide powerful meta-programming capabilities. This is generally done at runtime with additional memory used for storing metadata - such as types and method signatures. But they also provide the same power for people reverse engineering your code.\nLet’s look at Objective-C, a simple code snippet:\n@interface MyObject : NSObject @end @implementation MyObject { NSInteger _number; } - (void)doSomething { _number++; NSLog(@\u0026#34;The %@\u0026#34;, [self _doSomethingSpecial:_number]); } - (NSString *)_doSomethingSpecial:(NSInteger)number { return [NSString stringWithFormat:@\u0026#34;Number: %d\u0026#34;, number]; } @end Simple enough, but what if we don’t have the source? Let’s step back to how Objective-C works…\nThe Objective-C 2.0 Runtime In the early days, Objective-C compiled to C. To be compatible with C, it used symbols that would normally be invalid for C. This explains why Objective-C uses @ for many of its keywords.\nIn fact, Objective-C methods are simply c-functions. So lets look at how -[_doSomethingSpecial:] would be defined in C:\nid __methImpl_MyObject_doSomethingSpecial_(id self, SEL _cmd, NSInteger number) { return objc_msgSend([NSString class], sel_registerName(\u0026#34;stringWithFormat:\u0026#34;), @\u0026#34;Number: %d\u0026#34;, number); } Yes, the name is still -[MyObject _doSomethingSpecial:]. If you use a debugger, you can pause on this method by that name.\nHeader Dumping But how might you get the name to begin with? class-dump.\nclass-dump allows you to generate headers from the Mach-O binary file. Using that, you can learn of the method name.\nUsing class-dump on the source above would generate something like:\n@interface MyObject : NSObject { int _number; } - (void)doSomething; - (id)_doSomethingSpecial:(int)arg1; @end What’s most noticeably missing are all the Objective-C types. Most of the Objective-C types are stripped at compile-time (properties are the exception).\nBut getting the types just takes some more laborious effort. No problem, it’s just a bit more work to walk through it using a debugger.\nOf course, if you like reading assembly, you can using something like Hopper to open the binary files and read the implementation.\nUsing the Debugger All Objective-C methods are converted to objc_msgSend’s. So setting a break at a message send invocation, you can read the registers at the current point in the debugger:\n{\u0026lt;2\u0026gt;} Objective-C uses the same calling conventions of C for the order of registers it uses for x86_64:\n$rdi is the first argument. The object receiving the method invocation in ObjC. $rsi is the second argument. The selector being sent (aka, the _cmd variable). $rdx is the third argument. The first argument of an ObjC method invocation if it uses one. $rcx is the fourth argument. The second argument of an ObjC method. $r8 is the fifth. $r9 is the sixth. Further arguments are placed on the stack (relative to the $rbp stack register). (It’s worth noting that variadic argument parameters behave differently.)\nAfter you step over the Objective-C message send (or any function invocation), the return value is stored on the $rax register.\nAs part of the ABI calling convention, there are generally function prologues and epilogues which saves and restores stack and register values as appropriate. To get a good picture of the registers contents for the function. You can set a breakpoint in the debugger at a memory address:\nlldb\u0026gt; break set --addr 0xdeadbeef Combining Everything So lets have a look at the assembly in the debugger:\n$ lldb # assuming app is already running # attach to the application; pauses it lldb\u0026gt; attach MyApp # sets the breakpoint by name lldb\u0026gt; break set --name \u0026#39;-[MyObject _doSomethingSpecial:]\u0026#39; # resume the application lldb\u0026gt; cont # do stuff in app to trigger the breakpoint # see assembly at breakpoint lldb\u0026gt; dis # set breakpoint after the function prolog found using dis lldb\u0026gt; break set --addr 0x12345678 # continue to breakpoint we just set lldb\u0026gt; cont # read the registers lldb\u0026gt; reg read # reads from $rdi register # and returns [$rdi debugDescription] lldb\u0026gt; po $rdi \u0026lt;MyObject: 0xdeadbeef\u0026gt; # returns c-type lldb\u0026gt; p $rdi (unsigned long)0xdeadbeef Want more? Check out An Interesting Approach to Reverse Engineering Apps. Or read up on Gwynne Raskind’s multi-part series on disassembly (part 1, part 2, part 3).\nAlso, you might like my talk on this.\n","permalink":"http://localhost:1313/2014/03-reverse-engineering-objective-c.html","summary":"\u003cp\u003eLanguages that have dynamic introspection provide powerful meta-programming\ncapabilities. This is generally done at runtime with additional memory used for\nstoring metadata - such as types and method signatures. But they also provide\nthe same power for people reverse engineering your code.\u003c/p\u003e\n\u003cp\u003eLet’s look at Objective-C, a simple code snippet:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-objc\" data-lang=\"objc\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003e@interface\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eMyObject\u003c/span\u003e : \u003cspan style=\"color:#a6e22e\"\u003eNSObject\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003e@end\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003e@implementation\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eMyObject\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    NSInteger _number;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e- (\u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e)\u003cspan style=\"color:#a6e22e\"\u003edoSomething\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    _number\u003cspan style=\"color:#f92672\"\u003e++\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    NSLog(\u003cspan style=\"color:#e6db74\"\u003e@\u0026#34;The %@\u0026#34;\u003c/span\u003e, [self _doSomethingSpecial:_number]);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e- (NSString \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e)\u003cspan style=\"color:#a6e22e\"\u003e_doSomethingSpecial:\u003c/span\u003e(NSInteger)number\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e [NSString stringWithFormat:\u003cspan style=\"color:#e6db74\"\u003e@\u0026#34;Number: %d\u0026#34;\u003c/span\u003e, number];\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003e@end\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSimple enough, but what if we don’t have the source? Let’s step back to how\nObjective-C works…\u003c/p\u003e","title":"Reverse Engineering Objective-C"},{"content":"It’s great to use classic algorithms to solve problems at hand. Take this problem of ellipsis:\nFor a given text. Fit the maximum number of words that fits in the given size, append “… More” if there was truncation.\nNo, NSLineBreakModeTailTruncation will not work. We need different text.\nThe näive solution would simply to cut a word one-by-one until it fits with a custom ellipsis text:\n@implementation NSString (CustomEllipsis) - (NSString *)textThatFitsSize:(CGSize)size ellipsisText:(NSString *)text { CGSize infiniteSize = CGSizeMake(size.width, INFINITY); CGSize fullSize = [text boundingRectWithSize:infiniteSize options:NSStringDrawingUsesFontLeading|NSStringDrawingUsesLineFragmentOrigin context:nil].size; // if text fits if (fullSize.height \u0026lt;= size.height) { return text; } NSString *finalString = nil; // if text doesn\u0026#39;t fit NSMutableArray *words = [[text componentsSeparatedByString:@\u0026#34; \u0026#34;] mutableCopy]; while (fullSize.height \u0026gt; size.height) { [words removeLastObject]; finalString = [words componentsJoinByString:@\u0026#34; \u0026#34;]; finalString = [finalString stringByAppendString:@\u0026#34;... MORE\u0026#34;]; fullSize = [modifiedString boundingRectWithSize:infiniteSize options:NSStringDrawingUsesFontLeading|NSStringDrawingUsesLineFragmentOrigin context:nil].size; } return finalString; } @end Run that in a table cell and you’ve got performance problems!\nBut this is a perfect fit for our standard computer science search algorithm. Let’s look at the problem again:\nWe want to find the number of words that can be allowed to display.\nIf we visualize the possible solutions, it’s just like searching through a sorted array items:\nNumber of words that fit in the given size: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] The slight change we have to make from the traditional algorithm is ensure our algorithm remembers the number words it last seen that fits the given bound box. So if the final “item” we reach doesn’t fit, we know a fall-back that fits.\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ^ Check (fits) + remember [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ^ Does not fit [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ^ Fits + remember [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ^ Does not fit Selects 6 words. The performance improvement great because checking of the comparison fits is expensive. This matches the same cost function of Big-O notation, where number of items “visited” is measured.\nFinally, those four years of CS paid off once :)\n","permalink":"http://localhost:1313/2014/02-adapting-binary-search.html","summary":"\u003cp\u003eIt’s great to use classic algorithms to solve problems at hand. Take this\nproblem of ellipsis:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFor a given text. Fit the maximum number of words that fits in the given size,\nappend “… More” if there was truncation.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eNo, \u003ccode\u003eNSLineBreakModeTailTruncation\u003c/code\u003e will not work. We need different text.\u003c/p\u003e\n\u003cp\u003eThe näive solution would simply to cut a word one-by-one until it fits with a\ncustom ellipsis text:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-objc\" data-lang=\"objc\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003e@implementation\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eNSString\u003c/span\u003e (CustomEllipsis)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e- (NSString \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e)\u003cspan style=\"color:#a6e22e\"\u003etextThatFitsSize:\u003c/span\u003e(CGSize)size \u003cspan style=\"color:#a6e22e\"\u003eellipsisText:\u003c/span\u003e(NSString \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e)text\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    CGSize infiniteSize \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e CGSizeMake(size.width, INFINITY);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    CGSize fullSize \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [text boundingRectWithSize:infiniteSize options:NSStringDrawingUsesFontLeading\u003cspan style=\"color:#f92672\"\u003e|\u003c/span\u003eNSStringDrawingUsesLineFragmentOrigin\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                              context:nil].size;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// if text fits\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e (fullSize.height \u003cspan style=\"color:#f92672\"\u003e\u0026lt;=\u003c/span\u003e size.height) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e text;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    NSString \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003efinalString \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e nil;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// if text doesn\u0026#39;t fit\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    NSMutableArray \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003ewords \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [[text componentsSeparatedByString:\u003cspan style=\"color:#e6db74\"\u003e@\u0026#34; \u0026#34;\u003c/span\u003e] mutableCopy];\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ewhile\u003c/span\u003e (fullSize.height \u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e size.height) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        [words removeLastObject];\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        finalString \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [words componentsJoinByString:\u003cspan style=\"color:#e6db74\"\u003e@\u0026#34; \u0026#34;\u003c/span\u003e];\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        finalString \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [finalString stringByAppendString:\u003cspan style=\"color:#e6db74\"\u003e@\u0026#34;... MORE\u0026#34;\u003c/span\u003e];\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        fullSize \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [modifiedString boundingRectWithSize:infiniteSize options:NSStringDrawingUsesFontLeading\u003cspan style=\"color:#f92672\"\u003e|\u003c/span\u003eNSStringDrawingUsesLineFragmentOrigin context:nil].size;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e finalString;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003e@end\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eRun that in a table cell and you’ve got performance problems!\u003c/p\u003e","title":"Adapting Binary Search"},{"content":"Every time you look at a new (or familiar) technology. You should ask: What are the tradeoffs?\nIt\u0026rsquo;s obvious to see the benefits of something - it\u0026rsquo;s generally advertised everywhere. Everyone is always shouting the the pros of X.\n\u0026ldquo;X does Y easier\u0026rdquo; \u0026ldquo;X does Y faster\u0026rdquo; \u0026ldquo;X integrates with Y\u0026rdquo; Pros tend to flood the internet way more than cons:\nX makes Z harder X makes Z slower X locks you into Y X does Y, at the expense of Z These are harder to find. Especially when the library is relatively new. But you can imagine based on how critical it is on your software stack.\nFor example, but I\u0026rsquo;m not exclusively selecting, Mongodb. It is easier and faster is than a traditional SQL database, but that\u0026rsquo;s because it sacrifices many capabilities that a SQL database provides:\nfsync (is off by default) locks per database no transactions (you can atomically update a document) relationships - which turns out to be useful for many applications. documents have a max size limit. doesn\u0026rsquo;t ensure data integrity; especially for single servers. Now, there are reasons why you might want to use it - although I personally feel like other NoSQL options solve those problems better. But know what limitations and tradeoffs you\u0026rsquo;re making.\n","permalink":"http://localhost:1313/2014/01-evaluating-technologies.html","summary":"\u003cp\u003eEvery time you look at a new (or familiar) technology. You should ask: What are\nthe tradeoffs?\u003c/p\u003e\n\u003cp\u003eIt\u0026rsquo;s obvious to see the benefits of something - it\u0026rsquo;s generally advertised\neverywhere. Everyone is always shouting the the pros of X.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026ldquo;X does Y easier\u0026rdquo;\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;X does Y faster\u0026rdquo;\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;X integrates with Y\u0026rdquo;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePros tend to flood the internet way more than cons:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eX makes Z harder\u003c/li\u003e\n\u003cli\u003eX makes Z slower\u003c/li\u003e\n\u003cli\u003eX locks you into Y\u003c/li\u003e\n\u003cli\u003eX does Y, at the expense of Z\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese are harder to find. Especially when the library is relatively new. But you\ncan imagine based on how critical it is on your software stack.\u003c/p\u003e","title":"Evaluating New Techonologies"},{"content":"Lazy data structures are a powerful abstraction can increase the readability of your program while encouraging separation of concerns.\nWhat are they? Simply put, they are data structures that \u0026ldquo;realize\u0026rdquo; what they contain when they\u0026rsquo;re needed (or right before they\u0026rsquo;re needed).\nWhat can you do with lazy data structures? How about a page-scraper that paginates as needed:\n# pseudocode seed_url = \u0026#34;http://example.com/page/\u0026#34; # generate a lazy list of urls: # - http://example.com/page/1 # - http://example.com/page/2 # - etc. urls = lazy { for (i = 0; i \u0026lt; 100; i++) { yield seed_url + string(i) } } # a lazy list of html pages pages = map(urls, fetchURLPageContents) # a lazy list of list of links links_per_page = map(pages, extractLinksFromHTML) # flatten to just a lazy list of links links = join(links_per_page) # do stuff with links for link in links { record(link) } This creates a powerful abstract that separate tasks your program needs to get done behind an implicit interface. The ending for loop doesn\u0026rsquo;t need to know that those links came from multiple page fetches or the file system. If the loop short-circuited, then it minimizes the number of unnecessary fetches.\nAs a fun experiment, I recently built Clojure\u0026rsquo;s sequence abstraction in Objective-C. Clojure\u0026rsquo;s Sequences are based on LISP\u0026rsquo;s famous linked list, converted to an interface that provides uniform api for a wide range of data structures in Clojure. It\u0026rsquo;s simple:\n@protocol Sequence \u0026lt;NSObject\u0026gt; - (id)firstObject; // clojure: (first seq); nil indicates end - (id\u0026lt;Sequence\u0026gt;)remainingSequence; // clojure: (rest seq) @end A variety of data structures can fit this interface at the potential sacrifice of performance of the underlying data structure:\nLinked Lists Arrays (remainingSequence would just drop the first element) Dictionary (each element is the key-value pair \u0026ndash; which can also be represented as a sequence) Trees (firstObject is the root, remainingSequence can be children) More interestingly, a lazy sequence can also be built from this interface. Lazy data structures only realize their contents as needed. They aren\u0026rsquo;t as complicated to implement as it sounds. Here\u0026rsquo;s a näive implementation based on the Clojure\u0026rsquo;s Java implementation:\n// LazySequence.h @interface LazySequence : NSObject \u0026lt;Sequence\u0026gt; // clojure equivalent to (lazy-seq (block)) - (instancetype)initWithBlock:(id\u0026lt;Sequence\u0026gt;(^)())block; @end // LazySequence.m @interface LazySequence () @property (nonatomic, copy) id\u0026lt;Sequence\u0026gt;(^block)(); @property (nonatomic) id blockValue; @property (nonatomic) id\u0026lt;Sequence\u0026gt; sequenceValue; @end @implementation LazySequence - (instancetype)initWithBlock:(id\u0026lt;Sequence\u0026gt;(^)())block { if (self = [super init]) { self.block = block; } return self; } - (id)firstObject { return [[self evaluateSequence] firstObject]; } - (id\u0026lt;Sequence\u0026gt;)remainingSequence { return [[self evaluateSequence] remainingSequence]; } #pragma mark - Private - (id)evaluateBlock { @synchronized (self) { if (self.block) { self.blockValue = self.block(); self.block = nil; } return self.blockValue; } } - (id\u0026lt;Sequence\u0026gt;)evaluateSequence { [self evaluateBlock]; @synchronize (self) { if (self.blockValue) { id value = self.blockValue; self.blockValue = nil; while ([self.block isKindOfClass:[LazySequence class]]) { value = [value evaluateBlock]; } self.sequenceValue = value; } return self.sequenceValue; } } @end While it might not be a typical first attempt at a lazy sequence, but it does have some interesting characteristics:\nThere is locking to support access on multiple threads It is readonly/immutable (assuming you don\u0026rsquo;t do any runtime magic) It stores an intermediate value - the sequence returned directly from the block and the \u0026ldquo;final\u0026rdquo; sequence after flattening any potentially recursive LazySequence. There is an isKindOfClass: check, ew. But lazy, higher-ordered functions (map, filter, reduce, etc.) can be implemented from this:\nid\u0026lt;Sequence\u0026gt; filterSequence(id\u0026lt;Sequence\u0026gt; seq, BOOL(^filter)(id value)) { if (![seq firstObject]) { return [ConcreteSequence emptySequence]; } return [[LazySequence alloc] initWithBlock:^id(id obj){ if (filter(obj)) { return [[ConcreteSequence alloc] initWithFirstObject:obj remainingSequence:filterSequence([self remainingSequence], filter)]; } else { return filterSequence([self remainingSequence]); } }]; } The Sequence abstraction lends itself to allow easy lazy evaluation, but other interface designs can be created to support more complex data structures while maintaining better performance than Sequence: such as a lazy dictionary that doesn\u0026rsquo;t require walking key-value pairs and instead only lazily realizes values).\nThere are tradeoffs for a relatively elegant design. You lose potential performance gains for using the abstaction \u0026ndash; like random access on your data structure\u0026rsquo;s elements. Also, laziness makes standard debugging techniques difficult. Stacktraces are less comprehensible because the execution order no longer reads procedurally. This is a common complaint of Haskell, where computation is lazily evaluated.\n","permalink":"http://localhost:1313/2014/04-objective-c-lazy-sequences.html","summary":"\u003cp\u003eLazy data structures are a powerful abstraction can increase the readability of\nyour program while encouraging separation of concerns.\u003c/p\u003e\n\u003cp\u003eWhat are they? Simply put, they are data structures that \u0026ldquo;realize\u0026rdquo; what they\ncontain when they\u0026rsquo;re needed (or right before they\u0026rsquo;re needed).\u003c/p\u003e\n\u003cp\u003eWhat can you do with lazy data structures? How about a page-scraper that\npaginates as needed:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-ruby\" data-lang=\"ruby\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# pseudocode\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eseed_url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;http://example.com/page/\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# generate a lazy list of urls:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# - http://example.com/page/1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# - http://example.com/page/2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# - etc.\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eurls \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e lazy {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e (i \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e; i \u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e100\u003c/span\u003e; i\u003cspan style=\"color:#f92672\"\u003e++\u003c/span\u003e) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eyield\u003c/span\u003e seed_url \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e string(i)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# a lazy list of html pages\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epages \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e map(urls, fetchURLPageContents)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# a lazy list of list of links\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elinks_per_page \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e map(pages, extractLinksFromHTML)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# flatten to just a lazy list of links\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elinks \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e join(links_per_page)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# do stuff with links\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e link \u003cspan style=\"color:#66d9ef\"\u003ein\u003c/span\u003e links {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    record(link)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis creates a powerful abstract that separate tasks your program needs to get\ndone behind an implicit interface. The ending for loop doesn\u0026rsquo;t need to know that\nthose links came from multiple page fetches or the file system. If the loop\nshort-circuited, then it minimizes the number of unnecessary fetches.\u003c/p\u003e","title":"Objective-C: Lazy Sequences"},{"content":" I\u0026rsquo;m a software engineer passionate about software engineering - which is the never-ending challenge of balance of perfection and shipping.\nIn the past, I was a consultant working on iOS applications using the C-family of languages and Swift. Clients ranged from early stealth startups to Fortune 500 companies. In iOS, I\u0026rsquo;m probably best known for work on Nimble or Cedar or giving some talks in the early days of Swift. Although, I\u0026rsquo;ve personally learned the most while making Hydrant.\nBefore working on iOS, I\u0026rsquo;ve dabbled in teaching (programming) and various dynamic languages (Python, Ruby, Perl, PHP, JavaScript, ActionScript/Flash, etc.).\nYou can find me coding on GitHub, or occasionally writing on my blog here. The blog is mostly for solidifying thoughts in the narrow-bandwidth of writing. Although, I also tend to spend a lot of time doing deep work in various programming topics that may or may not ever see the light of day.\nAfter consulting, I worked in Clojure, helping hair stylists sell hair extensions.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/profile2.png\" alt=\"Photo\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m a software engineer passionate about software engineering - which is the\nnever-ending challenge of balance of perfection and shipping.\u003c/p\u003e\n\u003cp\u003eIn the past, I was a \u003ca href=\"https://pivotal.io/labs\"\u003econsultant\u003c/a\u003e working on iOS\napplications using the C-family of languages and Swift. Clients ranged from\nearly stealth startups to Fortune 500 companies. In iOS, I\u0026rsquo;m probably best known\nfor work on \u003ca href=\"https://github.com/quick/nimble\"\u003eNimble\u003c/a\u003e or\n\u003ca href=\"https://github.com/pivotal/cedar\"\u003eCedar\u003c/a\u003e or giving some talks in the early days\nof Swift. Although, I\u0026rsquo;ve personally learned the most while making\n\u003ca href=\"https://github.com/jeffh/Hydrant\"\u003eHydrant\u003c/a\u003e.\u003c/p\u003e","title":"Hi there, I'm Jeff!"}]